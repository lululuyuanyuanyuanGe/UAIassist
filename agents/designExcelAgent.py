import sys
from pathlib import Path
import json

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated, Union
from datetime import datetime

from utilities.modelRelated import invoke_model, invoke_model_with_tools

from pathlib import Path
# Create an interactive chatbox using gradio
import gradio as gr
from dotenv import load_dotenv


from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool

# import other agents
from agents.processUserInput import ProcessUserInputAgent
from agents.recallFilesAgent import RecallFilesAgent
from agents.filloutTable import FilloutTableAgent


class DesignExcelState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    next_node: str
    template_structure: str
    user_feedback: str
    session_id: str

class DesignExcelAgent:
    def __init__(self):
        self.memory = MemorySaver()
        self.graph = self._build_graph().compile(checkpointer=self.memory)


    def _build_graph(self) -> StateGraph:
        graph = StateGraph(DesignExcelState)
        graph.add_node("collect_user_requirement", self._collect_user_requirement)
        graph.add_node("design_excel_template", self._design_excel_template)
        graph.add_edge(START, "collect_user_requirement")
        graph.add_conditional_edges("collect_user_requirement", self._route_after_collect_user_requirement)
        graph.add_edge("design_excel_template", END)
        return graph
    

    def _create_initial_state(self, session_id: str) -> DesignExcelState:
        """This function initializes the state of the design excel agent"""
        return {
            "messages": [],
            "next_node": "collect_user_requirement",
            "template_structure": "",
            "user_feedback": "",
            "session_id": session_id
        }

    def _collect_user_requirement(self, state: DesignExcelState) -> DesignExcelState:
        """è¯¢é—®ç”¨æˆ·æ¨¡ç‰ˆéœ€æ±‚ï¼Œæˆ–æ”¹è¿›æ„è§"""
        print("\nðŸ” å¼€å§‹æ‰§è¡Œ: _collect_user_requirement")
        print("=" * 50)
        
        if not state["template_structure"]:
            print("å¤§æ¨¡åž‹è®¾è®¡çš„æ¨¡æ¿")

        user_feedback = input("è¯·è¾“å…¥æ‚¨çš„åé¦ˆï¼š")
        print("âœ… _collect_user_requirement æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        return {"user_feedback": user_feedback}

    def _route_after_collect_user_requirement(self, state: DesignExcelState) -> str:
        """æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè®¾è®¡æ¨¡ç‰ˆ"""
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬åˆ†æžä¸“å®¶ï¼Œæ ¹æ®æ”¶é›†åˆ°çš„ç”¨æˆ·è¾“å…¥æ€»ç»“ä½ æ¥åˆ¤æ–­ä¸‹ä¸€æ­¥çš„è·¯ç”±èŠ‚ç‚¹ï¼Œ
        å¦‚æžœç”¨æˆ·ç»™å‡ºäº†è‚¯å®šçš„ç­”å¤åˆ™è¿”å›ž
        END
        å¦åˆ™è¿”å›ž
        design_excel_template
        ä½ çš„è¿”å›žä¸ºçº¯æ–‡æœ¬ï¼Œä¸è¦è¿”å›žä»»ä½•å…¶ä»–å†…å®¹æˆ–è§£é‡Š
        """

        response = invoke_model(model_name="gpt-4o", 
                                           messages=[SystemMessage(content=system_prompt)])
        print("å¤§æ¨¡åž‹è¿”å›žçš„è·¯ç”±èŠ‚ç‚¹æ˜¯ï¼š", response)
        return response


    def _design_excel_template(self, state: DesignExcelState) -> DesignExcelState:
        """æ ¹æ®ç”¨æˆ·éœ€æ±‚ï¼Œè®¾è®¡æ¨¡ç‰ˆ"""
        print("\nðŸ’¬ å¼€å§‹æ‰§è¡Œ: _chat_with_user_to_determine_template")
        print("=" * 50)
        
        # Check if we have tool results from previous interaction
        if state.get("messages") and len(state["messages"]) > 0:
            latest_message = state["messages"][-1]
            user_context = latest_message.content
            print(f"ðŸ“‹ ç”¨æˆ·ä¸Šä¸‹æ–‡: {user_context}")
            user_context = json.loads(user_context)
            if isinstance(user_context, list):
                print("ðŸ” ç”¨æˆ·ä¸Šä¸‹æ–‡æ˜¯åˆ—è¡¨:" , user_context[0])
                user_context = user_context[0]
                # Fix: Parse the JSON string again since user_context[0] is still a string
                if isinstance(user_context, str):
                    user_context = json.loads(user_context)
                user_context = user_context["summary"]
            else:
                user_context = user_context["summary"]
        else:
            user_context = "ç”¨æˆ·éœ€è¦ç¡®å®šè¡¨æ ¼ç»“æž„"
        print(f"ðŸ” ç”¨æˆ·ä¸Šä¸‹æ–‡: {user_context}")

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªExcelè¡¨æ ¼è®¾è®¡ä¸“å®¶ï¼Œä½ éœ€è¦è·Ÿæ ¹æ®ç”¨æˆ·çš„éœ€æ±‚ï¼Œå¹¶ä¸”å‚è€ƒæˆ‘ä»¬çŸ¥è¯†åº“é‡Œå·²æ”¶å½•çš„ä¿¡æ¯ï¼Œ
        æ¥è®¾è®¡ä¸€ä¸ªç¬¦åˆç”¨æˆ·éœ€æ±‚çš„è¡¨æ ¼ã€‚çŸ¥è¯†åº“é‡Œæ”¶å½•äº†æ‰€æœ‰å¯ä»¥åˆ©ç”¨çš„è¡¨æ ¼æˆ–è€…æ–‡æ¡£ï¼Œè¡¨æ ¼æ˜¯ç”¨æˆ·ä¸Šä¼ ç»™æˆ‘ä»¬çš„å¸¦æœ‰åŽŸå§‹æ•°æ®çš„è¡¨æ ¼ï¼Œå¹¶ä¸”æˆ‘ä»¬
        å·²ç»æ•´ç†å‡ºäº†è¡¨æ ¼ç»“æž„ï¼Œä»¥åŠæ€»ç»“ï¼ŒåŒæ ·çš„ï¼Œæ–‡æ¡£æ˜¯ç”¨æˆ·å·²ç»ä¸Šä¼ çš„ç”¨äºŽè¾…åŠ©å¡«å†™è¡¨æ ¼çš„æ–‡ä»¶ï¼Œé‡Œé¢åŒ…å«ä¸€äº›æ”¿ç­–ä¿¡æ¯ï¼Œè¿™äº›ä¿¡æ¯åŠ ä¸Š
        å·²æœ‰æ•°æ®å¯ä»¥è®©æˆ‘ä»¬æŽ¨ç†å‡ºæ–°çš„æ•°æ®ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è¿™äº›å·²æœ‰æ•°æ®ï¼Œæ–‡æ¡£å’Œç”¨æˆ·éœ€æ±‚è®¾è®¡å‡ºä¸€ä¸ªæ–°çš„Excelæ¨¡æ¿è¡¨æ ¼ã€‚ä½ ä¸€å®šè¦ç¡®ä¿
        è®¾è®¡å‡ºæ¥çš„è¡¨æ ¼ä¸­æ¯ä¸ªè¡¨å¤´éƒ½èƒ½æœ‰ç¡®åˆ‡çš„æ•°æ®æ¥æºï¼Œæˆ–è€…èƒ½æ ¹æ®å…¶ä»–ä¿¡æ¯æŽ¨ç†å‡ºæ¥ã€‚å¦å¤–æˆ‘ä¹Ÿä¼šæŠŠç”¨æˆ·çš„åé¦ˆä¿¡æ¯æˆ–è€…è®¾è®¡è¦æ±‚æä¾›ç»™ä½ 
        ä½ ä¹Ÿéœ€è¦å‚è€ƒè¿™äº›ä¿¡æ¯æ¥è®¾è®¡æ¨¡æ¿æˆ–è€…æ”¹è¿›è®¾è®¡ã€‚




        ç”¨æˆ·çš„éœ€æ±‚æ˜¯ï¼š{user_context}

        è¯·ä¸¥æ ¼éµå®ˆä»¥ä¸‹è¾“å‡ºè§„åˆ™
1. æå–è¡¨æ ¼çš„å¤šçº§è¡¨å¤´ç»“æž„ï¼š
   - ä½¿ç”¨åµŒå¥—çš„ key-value å½¢å¼è¡¨ç¤ºå±‚çº§å…³ç³»ï¼›
   - æ¯ä¸€çº§è¡¨å¤´åº”ä»¥å¯¹è±¡å½¢å¼å±•ç¤ºå…¶å­çº§å­—æ®µæˆ–å­è¡¨å¤´ï¼›
   - ä¸éœ€è¦é¢å¤–å­—æ®µï¼ˆå¦‚ nullã€isParent ç­‰ï¼‰ï¼Œä»…ä¿ç•™ç»“æž„æ¸…æ™°çš„å±‚çº§æ˜ å°„ï¼›

2. æä¾›ä¸€ä¸ªå¯¹è¯¥è¡¨æ ¼å†…å®¹çš„ç®€è¦æ€»ç»“ï¼š
   - å†…å®¹åº”åŒ…æ‹¬è¡¨æ ¼ç”¨é€”ã€ä¸»è¦ä¿¡æ¯ç±»åˆ«ã€é€‚ç”¨èŒƒå›´ç­‰ï¼›
   - è¯­è¨€ç®€æ´ï¼Œä¸è¶…è¿‡ 150 å­—ï¼›

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "è¡¨æ ¼ç»“æž„": {{
    "é¡¶å±‚è¡¨å¤´åç§°": {{
      "äºŒçº§è¡¨å¤´åç§°": [
        "å­—æ®µ1",
        "å­—æ®µ2"
      ]
    }}
  }},
  "è¡¨æ ¼æ€»ç»“": "è¯¥è¡¨æ ¼çš„ä¸»è¦ç”¨é€”åŠå†…å®¹è¯´æ˜Ž..."
}}



"""
        print("system_promptå’Œç”¨æˆ·äº¤äº’ç¡®å®šè¡¨æ ¼ç»“æž„:\n ", system_prompt)
        print("ðŸ“¤ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œè¡¨æ ¼ç»“æž„ç¡®å®š...")
        response = invoke_model(model_name="gpt-4o", 
                                           messages=[SystemMessage(content=system_prompt)])
        
        print("è¿”å›žç»“æžœï¼š", response)

        
        print("âœ… _chat_with_user_to_determine_template æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {"template_structure": str(response),
                "next_node": "design_excel_template"
                }
    
    def run_design_excel_agent(self, session_id: str) -> DesignExcelState:
        """Run the design excel agent"""
        state = self._create_initial_state(session_id)
        final_state = self.graph.invoke(state)
        return final_state