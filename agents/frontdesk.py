import sys
from pathlib import Path
import json

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated, Union
from datetime import datetime

from utilities.modelRelated import invoke_model, invoke_model_with_tools

from pathlib import Path
# Create an interactive chatbox using gradio
import gradio as gr
from dotenv import load_dotenv


from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage, ToolMessage
from langchain_core.tools import tool

# import other agents
from agents.processUserInput import ProcessUserInputAgent
from agents.recallFilesAgent import RecallFilesAgent
from agents.filloutTable import FilloutTableAgent

load_dotenv()

def append_strings(left: list[str], right: Union[list[str], str]) -> list[str]:
    """Custom reducer to append strings to a list"""
    if isinstance(right, list):
        return left + right
    else:
        return left + [right]
    

@tool
def _collect_user_input(session_id: str, AI_question: str) -> str:
    """è¿™æ˜¯ä¸€ä¸ªç”¨æ¥æ”¶é›†ç”¨æˆ·è¾“å…¥çš„å·¥å…·ï¼Œä½ éœ€è¦è°ƒç”¨è¿™ä¸ªå·¥å…·æ¥æ”¶é›†ç”¨æˆ·è¾“å…¥
    å‚æ•°ï¼š
        session_id: å½“å‰ä¼šè¯ID
        AI_question: å¤§æ¨¡å‹çš„é—®é¢˜
    è¿”å›ï¼š
        str: æ€»ç»“åçš„ç”¨æˆ·è¾“å…¥ä¿¡æ¯
    """

    print(f"ğŸ”„ å¼€å§‹æ”¶é›†ç”¨æˆ·è¾“å…¥ï¼Œå½“å‰ä¼šè¯ID: {session_id}")
    print(f"ğŸ’¬ AIé—®é¢˜: {AI_question}")
    
    processUserInputAgent = ProcessUserInputAgent()
    ai_message = AIMessage(content=AI_question)
    response = processUserInputAgent.run_process_user_input_agent(session_id = session_id, previous_AI_messages = ai_message)
    print(f"ğŸ”„ è¿”å›å“åº”: {response[:100]}...")
    return response
    

class FrontdeskState(TypedDict):
    chat_history: Annotated[list[str], append_strings]
    messages: Annotated[list[BaseMessage], add_messages]
    template_structure: str
    previous_node: str # Track the previous node
    session_id: str
    template_file_path: str
    table_summary: str
    headers_mapping: dict[str, str]
    recalled_xls_files: list[str]


class FrontdeskAgent:
    """
    ç”¨äºå¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ¨¡æ¿ï¼Œè‹¥æœªæä¾›æ¨¡æ¿ï¼Œå’Œç”¨æˆ·æ²Ÿé€šç¡®å®šè¡¨æ ¼ç»“æ„
    """



    def __init__(self, model_name: str = "gpt-4o"):
        self.model_name = model_name
        self.tools = [_collect_user_input]
        self.graph = self._build_graph()




    def _build_graph(self):
        """This function will build the graph of the frontdesk agent"""

        graph = StateGraph(FrontdeskState)

        graph.add_node("entry", self._entry_node)
        graph.add_node("collect_user_input", ToolNode(self.tools))
        graph.add_node("initial_collect_user_input", self._initial_collect_user_input)
        # graph.add_node("complex_template_handle", self._complex_template_analysis)  # Commented out as method is not implemented
        graph.add_node("simple_template_handle", self._simple_template_analysis)
        graph.add_node("chat_with_user_to_determine_template", self._chat_with_user_to_determine_template)
        graph.add_node("recall_files_agent", self._recall_files_agent)
        graph.add_node("fillout_table_agent", self._fillout_table_agent)

        graph.add_edge(START, "entry")
        graph.add_edge("entry", "initial_collect_user_input")
        graph.add_conditional_edges("initial_collect_user_input", self._route_after_initial_collect_user_input)
        graph.add_conditional_edges("collect_user_input", self._route_after_collect_user_input)
        graph.add_conditional_edges("chat_with_user_to_determine_template", self._route_after_chat_with_user_to_determine_template)
        graph.add_edge("simple_template_handle", "recall_files_agent")
        graph.add_edge("recall_files_agent", "fillout_table_agent")
        # graph.add_edge("recall_files_agent", END)
        graph.add_edge("fillout_table_agent", END)

        
        # Compile the graph to make it executable with stream() method
        # You can add checkpointer if needed: graph.compile(checkpointer=MemorySaver())
        return graph.compile()



    def _create_initial_state(self, session_id: str = "1") -> FrontdeskState:
        """This function will create the initial state of the frontdesk agent"""
        return {
            "chat_history": [],
            "template_structure": "",
            "messages": [],
            "messages_s": [],
            "table_structure": "",
            "session_id": session_id,
            "previous_node": "",
            "headers_mapping": {},
            "recalled_xls_files": []
        }


    def _entry_node(self, state: FrontdeskState) -> FrontdeskState:
        """This is the starting node of our frontdesk agent"""
        print("\nğŸš€ å¼€å§‹æ‰§è¡Œ: _entry_node")
        print("=" * 50)
        
        # Enrich this later, it should include a short description of the agent's ability and how to use it
        welcome_message = "ä½ å¥½ï¼Œæˆ‘æ˜¯ä¸€ä¸ªè¡¨æ ¼å¤„ç†åŠ©æ‰‹ï¼"
        print(f"ğŸ’¬ æ¬¢è¿æ¶ˆæ¯: {welcome_message}")
        
        print("âœ… _entry_node æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {
            "messages": [AIMessage(content=welcome_message)],
            "previous_node": "chat_with_user_to_determine_template"
        }
    

    def _initial_collect_user_input(self, state: FrontdeskState) -> FrontdeskState:
        """è°ƒç”¨ProcessUserInputAgentæ¥æ”¶é›†ç”¨æˆ·è¾“å…¥"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _initial_collect_user_input")
        print("=" * 50)
        
        session_id = state["session_id"]
        previous_AI_messages = state["messages"][-1]
        
        print(f"ğŸ“‹ ä¼šè¯ID: {session_id}")
        print("ğŸ”„ æ­£åœ¨è°ƒç”¨ProcessUserInputAgent...")
        
        processUserInputAgent = ProcessUserInputAgent()
        summary_message = processUserInputAgent.run_process_user_input_agent(session_id = session_id, previous_AI_messages = previous_AI_messages)
        print(f"ğŸ“¥ åŸå§‹è¿”å›ä¿¡æ¯ï¼š{summary_message}")
        
        # Handle the case where summary_message might be None
        if summary_message is None or len(summary_message) < 2:
            error_msg = "ç”¨æˆ·è¾“å…¥å¤„ç†å¤±è´¥ï¼Œè¯·é‡æ–°è¾“å…¥"
            print(f"âŒ {error_msg}")
            print("âœ… _initial_collect_user_input æ‰§è¡Œå®Œæˆ(é”™è¯¯)")
            print("=" * 50)
            return {
                "messages": [AIMessage(content=error_msg)],
                "template_file_path": "",
                "previous_node": "initial_collect_user_input"
            }
            
        print(f"ğŸ“Š è¿”å›ä¿¡æ¯JSON dumpï¼š{json.dumps(summary_message[0])}")
        
        print("âœ… _initial_collect_user_input æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        print("tempalte_file_paathåˆå§‹åŒ–: ", summary_message[1])
        return {
            "messages": [AIMessage(content=summary_message[0])],
            "template_file_path": summary_message[1],
            "previous_node": "initial_collect_user_input"
        }
        
    def _route_after_initial_collect_user_input(self, state: FrontdeskState) -> str:
        """åˆå§‹è°ƒç”¨ProcessUserInputAgentåï¼Œæ ¹æ®è¿”å›ä¿¡æ¯å†³å®šä¸‹ä¸€æ­¥çš„æµç¨‹"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_initial_collect_user_input")
        print("=" * 50)
        
        content = state['messages'][-1].content
        print(f"ğŸ“‹ stateæµ‹è¯•: {content}")
        
        # Check if content is JSON or plain text error message
        try:
            summary_message = json.loads(content)
            print(f"ğŸ“Š summary_messageæµ‹è¯•: {summary_message}")
            next_node = summary_message.get("next_node", "previous_node")
            print(f"ğŸ”„ è·¯ç”±å†³å®š: {next_node}")
            
            print("âœ… _route_after_initial_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
                
            if next_node == "complex_template":
                # Complex template handling not implemented yet, fallback to simple template
                print("âš ï¸ å¤æ‚æ¨¡æ¿å¤„ç†æš‚æœªå®ç°ï¼Œè½¬ä¸ºç®€å•æ¨¡æ¿å¤„ç†")
                return "simple_template_handle"
            elif next_node == "simple_template":
                return "simple_template_handle"
            else:
                return state.get("previous_node", "entry")  # Fallback to previous node
                
        except json.JSONDecodeError:
            # Content is plain text error message, not JSON
            print("âŒ å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½æ˜¯é”™è¯¯æ¶ˆæ¯")
            print("ğŸ”„ è·¯ç”±åˆ° chat_with_user_to_determine_template é‡æ–°å¼€å§‹")
            print("âœ… _route_after_initial_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "chat_with_user_to_determine_template"
        

    def _route_after_collect_user_input(self, state: FrontdeskState) -> str:
        """This node will route the agent to the next node based on the summary message from the ProcessUserInputAgent"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_collect_user_input")
        print("=" * 50)
        
        latest_message = state["messages"][-1]
        
        # This is a regular message, try to parse as JSON for routing
        summary_message_str = latest_message.content
        print(f"ğŸ“‹ åŸå§‹å†…å®¹: {summary_message_str}")
        
        try:
            summary_message_json = json.loads(summary_message_str)
            summary_message = json.loads(summary_message_json[0])
            print(f"ğŸ“Š summary_messageæµ‹è¯•: {summary_message}")
            next_node = summary_message.get("next_node", "previous_node")
            print(f"ğŸ”„ è·¯ç”±å†³å®š: {next_node}")
            
            print("âœ… _route_after_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
                
            if next_node == "complex_template":
                # Complex template handling not implemented yet, fallback to simple template
                print("âš ï¸ å¤æ‚æ¨¡æ¿å¤„ç†æš‚æœªå®ç°ï¼Œè½¬ä¸ºç®€å•æ¨¡æ¿å¤„ç†")
                return "simple_template_handle"
            elif next_node == "simple_template":
                return "simple_template_handle"
            else:
                return state.get("previous_node", "entry")  # Fallback to previous node
                
        except json.JSONDecodeError:
            # Content is plain text error message, not JSON
            print("âŒ å†…å®¹ä¸æ˜¯æœ‰æ•ˆçš„JSONï¼Œå¯èƒ½æ˜¯é”™è¯¯æ¶ˆæ¯")
            print("ğŸ”„ è·¯ç”±åˆ° chat_with_user_to_determine_template é‡æ–°å¼€å§‹")
            print("âœ… _route_after_collect_user_input æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "chat_with_user_to_determine_template"
            


    def _complex_template_analysis(self, state: FrontdeskState) -> FrontdeskState:
        """This node will be use to analyze the complex table template, we will skip for now"""
        print("\nğŸ”§ å¼€å§‹æ‰§è¡Œ: _complex_template_analysis")
        print("=" * 50)
        print("âš ï¸ å¤æ‚æ¨¡æ¿åˆ†æåŠŸèƒ½æš‚æœªå®ç°")
        print("âœ… _complex_template_analysis æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return state

    def _chat_with_user_to_determine_template(self, state: FrontdeskState) -> FrontdeskState:
        """This node will chat with the user to determine the template, when the template is not provided"""
        print("\nğŸ’¬ å¼€å§‹æ‰§è¡Œ: _chat_with_user_to_determine_template")
        print("=" * 50)
        
        # Check if we have tool results from previous interaction
        if state.get("messages") and len(state["messages"]) > 0:
            latest_message = state["messages"][-1]
            user_context = latest_message.content
            print(f"ğŸ“‹ ç”¨æˆ·ä¸Šä¸‹æ–‡: {user_context}")
            user_context = json.loads(user_context)
            if isinstance(user_context, list):
                print("ğŸ” ç”¨æˆ·ä¸Šä¸‹æ–‡æ˜¯åˆ—è¡¨:" , user_context[0])
                user_context = user_context[0]
                # Fix: Parse the JSON string again since user_context[0] is still a string
                if isinstance(user_context, str):
                    user_context = json.loads(user_context)
                user_context = user_context["summary"]
            else:
                user_context = user_context["summary"]
        else:
            user_context = "ç”¨æˆ·éœ€è¦ç¡®å®šè¡¨æ ¼ç»“æ„"
        print(f"ğŸ” ç”¨æˆ·ä¸Šä¸‹æ–‡: {user_context}")

        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ Excel è¡¨æ ¼ç”ŸæˆåŠ©æ‰‹ï¼Œç°åœ¨ä½ éœ€è¦å’Œç”¨æˆ·è¿›è¡Œå¯¹è¯ï¼Œæ¥ç¡®è®¤ç”¨æˆ·æƒ³è¦ç”Ÿæˆçš„è¡¨æ ¼ç»“æ„å†…å®¹ã€‚
è¡¨æ ¼å¯èƒ½æ¶‰åŠåˆ°å¤æ‚çš„å¤šçº§è¡¨å¤´ï¼Œå› æ­¤ä½ éœ€è¦å¼„æ¸…æ¥šæ‰€æœ‰çš„ç»“æ„å±‚çº§ï¼Œä¸æ–­è¯¢é—®ç”¨æˆ·ï¼Œç›´åˆ°ä½ ææ¸…æ¥šå…¨éƒ¨éœ€æ±‚ï¼Œå¹¶è¿”å›ä»¥ä¸‹æ ¼å¼ï¼š

1. æå–è¡¨æ ¼çš„å¤šçº§è¡¨å¤´ç»“æ„ï¼š
   - ä½¿ç”¨åµŒå¥—çš„ key-value å½¢å¼è¡¨ç¤ºå±‚çº§å…³ç³»ï¼›
   - æ¯ä¸€çº§è¡¨å¤´åº”ä»¥å¯¹è±¡å½¢å¼å±•ç¤ºå…¶å­çº§å­—æ®µæˆ–å­è¡¨å¤´ï¼›
   - ä¸éœ€è¦é¢å¤–å­—æ®µï¼ˆå¦‚ nullã€isParent ç­‰ï¼‰ï¼Œä»…ä¿ç•™ç»“æ„æ¸…æ™°çš„å±‚çº§æ˜ å°„ï¼›

2. æä¾›ä¸€ä¸ªå¯¹è¯¥è¡¨æ ¼å†…å®¹çš„ç®€è¦æ€»ç»“ï¼š
   - å†…å®¹åº”åŒ…æ‹¬è¡¨æ ¼ç”¨é€”ã€ä¸»è¦ä¿¡æ¯ç±»åˆ«ã€é€‚ç”¨èŒƒå›´ç­‰ï¼›
   - è¯­è¨€ç®€æ´ï¼Œä¸è¶…è¿‡ 150 å­—ï¼›

è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
{{
  "è¡¨æ ¼ç»“æ„": {{
    "é¡¶å±‚è¡¨å¤´åç§°": {{
      "äºŒçº§è¡¨å¤´åç§°": [
        "å­—æ®µ1",
        "å­—æ®µ2"
      ]
    }}
  }},
  "è¡¨æ ¼æ€»ç»“": "è¯¥è¡¨æ ¼çš„ä¸»è¦ç”¨é€”åŠå†…å®¹è¯´æ˜..."
}}

è¯·å¿½ç•¥æ‰€æœ‰ HTML æ ·å¼æ ‡ç­¾ï¼Œåªå…³æ³¨è¡¨æ ¼ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚

å¦‚æœç”¨æˆ·ä¿¡æ¯ä¸å¤Ÿè¯¦ç»†ï¼Œä½ å¯ä»¥è°ƒç”¨å·¥å…·æ¥æ”¶é›†æ›´å¤šç”¨æˆ·è¾“å…¥ã€‚å¦‚æœç”¨æˆ·ä¿¡æ¯å·²ç»è¶³å¤Ÿè¯¦ç»†ï¼Œè¯·ç›´æ¥è¿”å›è¡¨æ ¼ç»“æ„JSONï¼Œä¸è¦å†è°ƒç”¨å·¥å…·ã€‚
å½“å‰ä¼šè¯ID: {state["session_id"]}
å½“å‰æƒ…å†µ: {user_context}
"""
        print("system_promptå’Œç”¨æˆ·äº¤äº’ç¡®å®šè¡¨æ ¼ç»“æ„:\n ", system_prompt)
        print("ğŸ“¤ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œè¡¨æ ¼ç»“æ„ç¡®å®š...")
        response = invoke_model_with_tools(model_name="gpt-4o", 
                                           messages=[SystemMessage(content=system_prompt)], tools=self.tools)
        
        print("è¿”å›ç»“æœï¼š", response)

        # åˆ›å»ºAIMessageæ—¶éœ€è¦ä¿ç•™tool_callsä¿¡æ¯
        if hasattr(response, 'tool_calls') and response.tool_calls:
            # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œåˆ›å»ºåŒ…å«tool_callsçš„AIMessage
            ai_message = AIMessage(content=response.content or "", tool_calls=response.tool_calls)
            print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
        else:
            # å¦‚æœæ²¡æœ‰å·¥å…·è°ƒç”¨ï¼ŒåªåŒ…å«å†…å®¹
            ai_message = AIMessage(content=str(response.content) if hasattr(response, 'content') else str(response))
            print("ğŸ’¬ æ— å·¥å…·è°ƒç”¨ï¼Œè¿”å›å†…å®¹å“åº”")
        
        print("âœ… _chat_with_user_to_determine_template æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {"template_structure": str(response),
                "previous_node": "chat_with_user_to_determine_template",
                "messages": [ai_message]
                }
    
    def _route_after_chat_with_user_to_determine_template(self, state: FrontdeskState) -> str:
        """This node will route the agent to the next node based on the user's input"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_chat_with_user_to_determine_template")
        print("=" * 50)
        
        latest_message = state["messages"][-1]
        if hasattr(latest_message, "tool_calls") and latest_message.tool_calls:
            print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè·¯ç”±åˆ° collect_user_input")
            print("âœ… _route_after_chat_with_user_to_determine_template æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "collect_user_input"
        else:
            print("âœ… æ— å·¥å…·è°ƒç”¨ï¼Œè·¯ç”±åˆ° END")
            print("âœ… _route_after_chat_with_user_to_determine_template æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "recall_files_agent"

    def _simple_template_analysis(self, state: FrontdeskState) -> FrontdeskState:
        """å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„ç®€å•æ¨¡æ¿"""
        print("\nğŸ“‹ å¼€å§‹æ‰§è¡Œ: _simple_template_analysis")
        print("=" * 50)
        
        if state["previous_node"] == "chat_with_user_to_determine_template":
            latest_message = state["messages"][-1]
            summary_message_str = latest_message.content
            print(f"summary_message_stréªŒè¯: {summary_message_str}")
            template_file_path = json.loads(summary_message_str)[1]
        else:
            template_file_path = state["template_file_path"]
        # Handle the case where template_file_path might be a list

        print(f"ğŸ” Debug - template_file_path_raw: {template_file_path} (type: {type(template_file_path)})")
        print(f"template_file_path_raw: {template_file_path}")
        
        if isinstance(template_file_path, list):
            if len(template_file_path) > 0:
                template_file_path = Path(template_file_path[0])  # Take the first file
                print(f"ğŸ” Debug - Using first file from list: {template_file_path}")
            else:
                raise ValueError("template_file_path list is empty")
        else:
            template_file_path = Path(template_file_path)
            print(f"ğŸ” Debug - Using single file path: {template_file_path}")
        
        print(f"ğŸ“„ æ­£åœ¨è¯»å–æ¨¡æ¿æ–‡ä»¶: {template_file_path.name}")
        template_file_content = template_file_path.read_text(encoding="utf-8")
        print(f"ğŸ“Š æ¨¡æ¿æ–‡ä»¶å†…å®¹é•¿åº¦: {len(template_file_content)} å­—ç¬¦")

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡æ¡£åˆ†æä¸“å®¶ã€‚è¯·é˜…è¯»ç”¨æˆ·ä¸Šä¼ çš„ HTML æ ¼å¼çš„ Excel æ–‡ä»¶ï¼Œå¹¶å®Œæˆä»¥ä¸‹ä»»åŠ¡ï¼š
        ä½ ä¹Ÿå¯ä»¥è°ƒç”¨å·¥å…·æ¥æ”¶é›†ç”¨æˆ·è¾“å…¥ï¼Œæ¥å¸®åŠ©ä½ åˆ†æè¡¨æ ¼ç»“æ„ï¼Œæœ‰ä»»ä½•ä¸ç¡®å®šçš„åœ°æ–¹ä¸€å®šè¦è¯¢é—®ç”¨æˆ·ï¼Œç›´åˆ°ä½ å®Œå…¨æ˜ç¡®è¡¨æ ¼ç»“æ„ä¸ºæ­¢
        ä½ ä¸è¦æ‰€æœ‰é—®é¢˜éƒ½é—®ç”¨æˆ·ï¼Œè‡ªå·±æ ¹æ®htmlçš„ç»“æ„æ¥åˆ†æï¼Œå¦‚æœåˆ†æä¸å‡ºæ¥ï¼Œå†é—®ç”¨æˆ·
        1. æå–è¡¨æ ¼çš„å¤šçº§è¡¨å¤´ç»“æ„ï¼›
        - ä½¿ç”¨åµŒå¥—çš„ key-value å½¢å¼è¡¨ç¤ºå±‚çº§å…³ç³»ï¼›
        - æ¯ä¸€çº§è¡¨å¤´åº”ä»¥å¯¹è±¡å½¢å¼å±•ç¤ºå…¶å­çº§å­—æ®µæˆ–å­è¡¨å¤´ï¼›
        - ä¸éœ€è¦é¢å¤–å­—æ®µï¼ˆå¦‚ nullã€isParent ç­‰ï¼‰ï¼Œä»…ä¿ç•™ç»“æ„æ¸…æ™°çš„å±‚çº§æ˜ å°„ï¼›

        2. æä¾›ä¸€ä¸ªå¯¹è¯¥è¡¨æ ¼å†…å®¹çš„ç®€è¦æ€»ç»“ï¼›
        - å†…å®¹åº”åŒ…æ‹¬è¡¨æ ¼ç”¨é€”ã€ä¸»è¦ä¿¡æ¯ç±»åˆ«ã€é€‚ç”¨èŒƒå›´ç­‰ï¼›
        - è¯­è¨€ç®€æ´ï¼Œä¸è¶…è¿‡ 150 å­—ï¼›

        è¾“å‡ºæ ¼å¼å¦‚ä¸‹ï¼š
        {{
        "è¡¨æ ¼ç»“æ„": {{
            "é¡¶å±‚è¡¨å¤´åç§°": {{
            "äºŒçº§è¡¨å¤´åç§°": [
                "å­—æ®µ1",
                "å­—æ®µ2",
                ...
            ]
            }}
        }},
        "è¡¨æ ¼æ€»ç»“": "è¯¥è¡¨æ ¼çš„ä¸»è¦ç”¨é€”åŠå†…å®¹è¯´æ˜..."
        }}

        è¯·å¿½ç•¥æ‰€æœ‰ HTML æ ·å¼æ ‡ç­¾ï¼Œåªå…³æ³¨è¡¨æ ¼ç»“æ„å’Œè¯­ä¹‰ä¿¡æ¯ã€‚

        ã€æ³¨æ„äº‹é¡¹ã€‘
        ä¸è¦å°†è¾“å‡ºæ ¼å¼ç”¨```json```åŒ…è£¹ï¼Œç›´æ¥è¿”å›jsonæ ¼å¼çš„æ–‡æœ¬

        ä¸‹é¢æ˜¯ç”¨æˆ·ä¸Šä¼ çš„æ¨¡æ¿è¡¨æ ¼å†…å®¹:
        {template_file_content}
        """

        print("ğŸ“¤ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œæ¨¡æ¿åˆ†æ...")
        response = invoke_model(model_name="Pro/deepseek-ai/DeepSeek-V3", messages=[SystemMessage(content=prompt)])
        print("ğŸ“¥ LLMå“åº”æ¥æ”¶æˆåŠŸ")
        
        
        print("âœ… _simple_template_analysis æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {"template_structure": response,
                "previous_node": "simple_template_handle",
                "messages": [AIMessage(content=response)]
                }

    def _recall_files_agent(self, state: FrontdeskState) -> FrontdeskState:
        """This node will recall the files from the user"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _recall_files_agent")
        print("=" * 50)
        
        raw_template = state["template_structure"]
        print(f"ğŸ” æ¨¡æ¿ç»“æ„ç±»å‹: {type(raw_template)}")
        print(f"ğŸ” æ¨¡æ¿ç»“æ„å†…å®¹: {raw_template}")
        
        # Handle both string and dict types
        if isinstance(raw_template, str):
            try:
                template_structure = json.loads(raw_template)
                print("âœ… ä»JSONå­—ç¬¦ä¸²è§£ææ¨¡æ¿ç»“æ„")
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                return {"headers_mapping": {}}
        elif isinstance(raw_template, dict):
            template_structure = raw_template
            print("âœ… ç›´æ¥ä½¿ç”¨å­—å…¸ç±»å‹æ¨¡æ¿ç»“æ„")
        else:
            print(f"âŒ ä¸æ”¯æŒçš„æ¨¡æ¿ç»“æ„ç±»å‹: {type(raw_template)}")
            return {"headers_mapping": {}}
        
        # Extract table structure if it exists
        if "è¡¨æ ¼ç»“æ„" in template_structure:
            table_structure = template_structure["è¡¨æ ¼ç»“æ„"]
            print("âœ… æå–è¡¨æ ¼ç»“æ„éƒ¨åˆ†")
        else:
            table_structure = template_structure
            print("âš ï¸ ç›´æ¥ä½¿ç”¨æ•´ä¸ªç»“æ„ä½œä¸ºè¡¨æ ¼ç»“æ„")
            
        print(f"ğŸ” æœ€ç»ˆè¡¨æ ¼ç»“æ„: {table_structure}")

        recallFilesAgent = RecallFilesAgent()
        # Pass as JSON string to ensure consistent format
        recallFilesAgent_final_state = recallFilesAgent.run_recall_files_agent(
            template_structure=json.dumps(template_structure, ensure_ascii=False)
        )

        headers_mapping = recallFilesAgent_final_state.get("headers_mapping")
        return {"headers_mapping": headers_mapping,
                "recalled_xls_files": recallFilesAgent_final_state.get("original_xls_files")
                }
    


    def _fillout_table_agent(self, state: FrontdeskState) -> FrontdeskState:
        """This node will fill out the table based on the headers mapping"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _fillout_table_agent")
        print("=" * 50)
        # return state
        filloutTableAgent = FilloutTableAgent()
        print("æ¨¡æ¿è¡¨æ ¼æ–‡ä»¶1111111111", state["template_file_path"])
        print(f"ğŸ” å¡«å……è¡¨æ ¼çš„æ–‡ä»¶2: {state['recalled_xls_files']}")
        filloutTableAgent_final_state = filloutTableAgent.run_fillout_table_agent(
            session_id=state["session_id"],
            headers_mapping=state["headers_mapping"],
            data_file_path=state["recalled_xls_files"],
            template_file=state["template_file_path"][0]                                                                       
                                                                                          )
        print(f"ğŸ” å¡«å……è¡¨æ ¼å“åº”: {filloutTableAgent_final_state}")

        return state

    
    def run_frontdesk_agent(self, session_id: str = "1") -> None:
        """This function will run the frontdesk agent using stream method with interrupt handling"""
        print("\nğŸš€ å¯åŠ¨ FrontdeskAgent")
        print("=" * 60)
        
        initial_state = self._create_initial_state(session_id)
        config = {"configurable": {"thread_id": session_id}}
        current_state = initial_state

        while True:
            try:
                print(f"\nğŸ”„ æ‰§è¡ŒçŠ¶æ€å›¾ï¼Œå½“å‰ä¼šè¯ID: {session_id}")
                print("-" * 50)
                
                final_state = self.graph.invoke(current_state, config = config)
                if "__interrupt__" in final_state:
                    interrupt_value = final_state["__interrupt__"][0].value
                    print(f"ğŸ’¬ æ™ºèƒ½ä½“: {interrupt_value}")
                    user_response = input("ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„å›å¤: ")
                    current_state = Command(resume=user_response)
                    continue
                print("FrontdeskAgentæ‰§è¡Œå®Œæ¯•")
                break
                
            except Exception as e:
                print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                print("-" * 50)
                break

            

frontdesk_agent = FrontdeskAgent()
graph = frontdesk_agent.graph



if __name__ == "__main__":
    frontdesk_agent = FrontdeskAgent()
    frontdesk_agent.run_frontdesk_agent()