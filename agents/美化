import sys
from pathlib import Path
import io
import contextlib

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated
from datetime import datetime
from utilities.visualize_graph import save_graph_visualization
from utilities.message_process import build_BaseMessage_type, filter_out_system_messages
from utilities.file_process import (detect_and_process_file_paths, retrieve_file_content, read_txt_file, 
                                    process_excel_files_with_chunking, find_largest_file)
from utilities.modelRelated import invoke_model

import uuid
import json
import os
import pandas as pd
from bs4 import BeautifulSoup
from pathlib import Path
# Create an interactive chatbox using gradio
import gradio as gr
from dotenv import load_dotenv
import re

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
from langgraph.constants import Send
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, Interrupt, interrupt
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage
from langchain_core.tools import tool


# import other agents
from agents.processUserInput import ProcessUserInputAgent

load_dotenv()

class FilloutTableState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    session_id: str
    data_file_path: list[str]
    supplement_files_summary: str
    template_file: str
    template_file_completion_code: str
    fill_CSV_2_template_code: str
    combined_data: str
    filled_row: str
    error_message: str
    error_message_summary: str
    template_completion_code_execution_successful: bool
    CSV2Teplate_template_completion_code_execution_successful: bool
    retry: int
    combined_data_array: list[str]
    headers_mapping: str
    largest_file_row_num: int
    combined_html: str
    # Use lambda reducers for concurrent updates
    empty_row_html: Annotated[str, lambda old, new: new if new else old]
    headers_html: Annotated[str, lambda old, new: new if new else old]
    footer_html: Annotated[str, lambda old, new: new if new else old]
    CSV_data: Annotated[list[str], lambda old, new: new if new else old]



class FilloutTableAgent:
    def __init__(self):
        self.graph = self._build_graph()
        



    def _build_graph(self):
        """Build the LangGraph workflow for filling out tables"""
        graph = StateGraph(FilloutTableState)
        
        # Add nodes
        graph.add_node("combine_data_split_into_chunks", self._combine_data_split_into_chunks)
        graph.add_node("generate_CSV_based_on_combined_data", self._generate_CSV_based_on_combined_data)
        graph.add_node("transform_data_to_html", self._transform_data_to_html)
        graph.add_node("extract_empty_row_html", self._extract_empty_row_html)
        graph.add_node("extract_headers_html", self._extract_headers_html)
        graph.add_node("extract_footer_html", self._extract_footer_html)
        graph.add_node("combine_html_tables", self._combine_html_tables)
        graph.add_node("shield_for_transform_data_to_html", self._shield_for_transform_data_to_html)
        
        # Define the workflow
        graph.add_edge(START, "combine_data_split_into_chunks")
        graph.add_conditional_edges("combine_data_split_into_chunks", self._route_after_combine_data_split_into_chunks)
        graph.add_edge("extract_empty_row_html", "shield_for_transform_data_to_html")
        graph.add_edge("extract_headers_html", "shield_for_transform_data_to_html")
        graph.add_edge("extract_footer_html", "shield_for_transform_data_to_html")
        graph.add_edge("generate_CSV_based_on_combined_data", "shield_for_transform_data_to_html")
        graph.add_edge("shield_for_transform_data_to_html", "transform_data_to_html")
        graph.add_edge("transform_data_to_html", "combine_html_tables")
        graph.add_edge("combine_html_tables", END)
        

        
        # Compile the graph
        return graph.compile()

    
    def create_initialize_state(self, session_id: str,
                                 template_file: str = None,
                                 data_file_path: list[str] = None,
                                 headers_mapping: dict[str, str] = None,
                                 supplement_files_summary: str = "") -> FilloutTableState:
        """This node will initialize the state of the graph"""
        return {
            "messages": [],
            "session_id": session_id,
            "data_file_path": data_file_path, # excel files(xls) that has raw data
            "template_file": template_file, # txt file of template file in html format
            "template_file_completion_code": "",
            "fill_CSV_2_template_code": "",
            "combined_data": "",
            "filled_row": "",
            "error_message": "",
            "error_message_summary": "",
            "template_completion_code_execution_successful": False,
            "CSV2Teplate_template_completion_code_execution_successful": False,
            "retry": 0,
            "combined_data_array": [],
            "headers_mapping": headers_mapping,
            "CSV_data": [],
            "largest_file_row_num": 66,
            "supplement_files_summary": supplement_files_summary,
            "empty_row_html": "",
            "headers_html": "",
            "footer_html": "",
            "combined_html": ""
            
        }
    
    def _combine_data_split_into_chunks(self, state: FilloutTableState) -> FilloutTableState:
        """æ•´åˆæ‰€æœ‰éœ€è¦ç”¨åˆ°çš„æ•°æ®ï¼Œå¹¶ç”Ÿå°†å…¶åˆ†æ‰¹ï¼Œç”¨äºåˆ†æ‰¹ç”Ÿæˆè¡¨æ ¼"""
        # return
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ: _combine_data_split_into_chunks")
        print("=" * 50)
        
        try:
            # Get Excel file paths from state
            excel_file_paths = []
            print(f"ğŸ“‹ å¼€å§‹å¤„ç† {len(state['data_file_path'])} ä¸ªæ•°æ®æ–‡ä»¶")
            
            # Convert data files to Excel paths if they're not already
            for file_path in state["data_file_path"]:
                print(f"ğŸ“„ æ£€æŸ¥æ–‡ä»¶: {file_path}")
                if file_path.endswith('.txt'):
                    # Try to find corresponding Excel file
                    excel_path = file_path.replace('.txt', '.xlsx')
                    if Path(excel_path).exists():
                        excel_file_paths.append(excel_path)
                        print(f"âœ… æ‰¾åˆ°å¯¹åº”çš„Excelæ–‡ä»¶: {excel_path}")
                    else:
                        # Try .xls extension
                        excel_path = file_path.replace('.txt', '.xls')
                        if Path(excel_path).exists():
                            excel_file_paths.append(excel_path)
                            print(f"âœ… æ‰¾åˆ°å¯¹åº”çš„Excelæ–‡ä»¶: {excel_path}")
                        else:
                            print(f"âš ï¸ æœªæ‰¾åˆ°å¯¹åº”çš„Excelæ–‡ä»¶: {file_path}")
                elif file_path.endswith(('.xlsx', '.xls', '.xlsm')):
                    excel_file_paths.append(file_path)
                    print(f"âœ… ç›´æ¥ä½¿ç”¨Excelæ–‡ä»¶: {file_path}")
            
            if not excel_file_paths:
                print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„Excelæ–‡ä»¶")
                print("âœ… _combine_data_split_into_chunks æ‰§è¡Œå®Œæˆ(é”™è¯¯)")
                print("=" * 50)
                return {"combined_data_array": []}
            
            print(f"ğŸ“Š å‡†å¤‡å¤„ç† {len(excel_file_paths)} ä¸ªExcelæ–‡ä»¶è¿›è¡Œåˆ†å—")
            
            # Use the helper function to process and chunk files
            # Convert word_file_list to string for supplement content
            supplement_content = ""
            if state["supplement_files_summary"]:
                supplement_content = "=== è¡¥å……æ–‡ä»¶å†…å®¹ ===\n" + state["supplement_files_summary"]
                print(f"ğŸ“š è¡¥å……å†…å®¹é•¿åº¦: {len(supplement_content)} å­—ç¬¦")
            
            print("ğŸ”„ æ­£åœ¨è°ƒç”¨process_excel_files_with_chunkingå‡½æ•°...")
            print("state['headers_mapping']çš„ç±»å‹: ", type(state["headers_mapping"]))
            chunked_result = process_excel_files_with_chunking(excel_file_paths=excel_file_paths, 
                                                             session_id=state["session_id"],
                                                             chunk_nums=15, largest_file=None,  # Let function auto-detect
                                                             data_json_path="agents/data.json")
            
            # Extract chunks and row count from the result
            chunked_data = chunked_result["combined_chunks"]
            largest_file_row_count = chunked_result["largest_file_row_count"]
            
            print(f"âœ… æˆåŠŸç”Ÿæˆ {len(chunked_data)} ä¸ªæ•°æ®å—")
            print(f"ğŸ“Š æœ€å¤§æ–‡ä»¶è¡Œæ•°: {largest_file_row_count}")
            for chunk in chunked_data:
                print(f"==================ğŸ” æ•°æ®å— ==================:")
                print(chunk)
            print("âœ… _combine_data_split_into_chunks æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            
            return {
                "combined_data_array": chunked_data,
                "largest_file_row_num": largest_file_row_count
            }
            
        except Exception as e:
            print(f"âŒ _combine_data_split_into_chunks æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            print("âœ… _combine_data_split_into_chunks æ‰§è¡Œå®Œæˆ(é”™è¯¯)")
            print("=" * 50)
            return {
                "combined_data_array": []
            }

    def _route_after_combine_data_split_into_chunks(self, state: FilloutTableState) -> str:
        """å¹¶è¡Œæ‰§è¡Œæ¨¡æ¿ä»£ç çš„ç”Ÿæˆå’ŒCSVæ•°æ®çš„åˆæˆ"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_combine_data_split_into_chunks")
        print("=" * 50)
        
        print("ğŸ”„ åˆ›å»ºå¹¶è¡Œä»»åŠ¡...")
        sends = []
        sends.append(Send("generate_CSV_based_on_combined_data", state))
        sends.append(Send("extract_empty_row_html", state))
        sends.append(Send("extract_headers_html", state))
        sends.append(Send("extract_footer_html", state)) 
        print("âœ… åˆ›å»ºäº†4ä¸ªå¹¶è¡Œä»»åŠ¡:")
        print("   - generate_CSV_based_on_combined_data")
        print("   - extract_empty_row_html")
        print("   - extract_headers_html")
        print("   - extract_footer_html")
    
        
        print("âœ… _route_after_combine_data_split_into_chunks æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return sends
    
    def _generate_CSV_based_on_combined_data(self, state: FilloutTableState) -> FilloutTableState:
        """æ ¹æ®æ•´åˆçš„æ•°æ®ï¼Œæ˜ å°„å…³ç³»ï¼Œæ¨¡æ¿ç”Ÿæˆæ–°çš„æ•°æ®"""
        # return state
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ: _generate_CSV_based_on_combined_data")
        print("=" * 50)
        
#         system_prompt = f"""
# ä½ æ˜¯ä¸€åä¸“ä¸šä¸”ä¸¥è°¨çš„ç»“æ„åŒ–æ•°æ®å¡«æŠ¥ä¸“å®¶ï¼Œå…·å¤‡é€»è¾‘æ¨ç†å’Œè®¡ç®—èƒ½åŠ›ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®åŸå§‹æ•°æ®å’Œæ¨¡æ¿æ˜ å°„è§„åˆ™ï¼Œå°†æ•°æ®å‡†ç¡®è½¬æ¢ä¸ºç›®æ ‡ CSV æ ¼å¼ï¼Œè¾“å‡ºç»“æ„åŒ–ã€å¹²å‡€çš„æ•°æ®è¡Œã€‚

# ã€è¾“å…¥å†…å®¹ã€‘
# 1. æ¨¡æ¿è¡¨å¤´æ˜ å°„ï¼ˆJSON æ ¼å¼ï¼‰ï¼šæè¿°ç›®æ ‡è¡¨æ ¼æ¯ä¸€åˆ—çš„æ¥æºã€è®¡ç®—é€»è¾‘æˆ–æ¨ç†è§„åˆ™ï¼›
# 2. åŸå§‹æ•°æ®é›†ï¼šåŒ…æ‹¬è¡¨å¤´ç»“æ„çš„ JSON å’Œ CSV æ•°æ®å—ï¼Œå…¶ä¸­æ¯æ¡æ•°æ®è¡Œå‰ä¸€è¡Œæ ‡æ³¨äº†å­—æ®µåç§°ï¼Œç”¨äºè¾…åŠ©å­—æ®µåŒ¹é…ã€‚

# ã€ä»»åŠ¡æµç¨‹ã€‘
# 1. è¯·ä½ é€å­—æ®µåˆ†ææ¨¡æ¿è¡¨å¤´æ˜ å°„ï¼Œæ˜ç¡®è¯¥å­—æ®µçš„æ¥æºæˆ–æ¨ç†é€»è¾‘ï¼›
# 2. è‹¥å­—æ®µæ¥è‡ªåŸå§‹æ•°æ®ï¼Œè¯·å…ˆå®šä½æ¥æºå­—æ®µå¹¶æ ¡éªŒå…¶æ ¼å¼ï¼›
# 3. è‹¥å­—æ®µéœ€æ¨ç†ï¼ˆå¦‚æ—¥æœŸæ ¼å¼è½¬æ¢ã€å¹´é¾„è®¡ç®—ã€é€»è¾‘åˆ¤æ–­ç­‰ï¼‰ï¼Œè¯·å…ˆåœ¨è„‘ä¸­é€æ­¥æ¨å¯¼ï¼Œç¡®ä¿æ€è·¯æ¸…æ™°ï¼›
# 4. è‹¥å­—æ®µéœ€è®¡ç®—ï¼Œè¯·å…ˆæ˜ç¡®æ‰€éœ€å…¬å¼å¹¶é€æ­¥è®¡ç®—å‡ºç»“æœï¼›
# 5. åœ¨å®Œæˆæ‰€æœ‰å­—æ®µæ¨ç†åï¼Œå†å°†ç»“æœæŒ‰ç…§å­—æ®µé¡ºåºåˆå¹¶ä¸ºä¸€è¡Œ CSV æ•°æ®ï¼›
# 6. åœ¨æ¯æ¬¡è¾“å‡ºå‰ï¼Œè¯·å…ˆ**åœ¨è„‘ä¸­é€é¡¹éªŒè¯å­—æ®µæ˜¯å¦åˆç†ã€æ ¼å¼æ˜¯å¦è§„èŒƒ**ã€‚

# ğŸ’¡ è¯·ä½ åƒä¸€ä½äººç±»ä¸“å®¶ä¸€æ ·ï¼Œ**ä¸€æ­¥ä¸€æ­¥æ€è€ƒå†åšå†³å®š**ï¼Œä¸è¦è·³è¿‡ä»»ä½•é€»è¾‘è¿‡ç¨‹ã€‚

# ã€è¾“å‡ºè¦æ±‚ã€‘
# - ä»…è¾“å‡ºçº¯å‡€çš„ CSV æ•°æ®è¡Œï¼Œä¸åŒ…å«è¡¨å¤´ã€æ³¨é‡Šæˆ–ä»»ä½•å¤šä½™å†…å®¹ï¼›
# - ä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”å­—æ®µï¼›
# - æ¯è¡Œæ•°æ®å­—æ®µé¡ºåºå¿…é¡»ä¸æ¨¡æ¿è¡¨å¤´æ˜ å°„å®Œå…¨ä¸€è‡´ï¼›
# - ä¸¥ç¦é—æ¼å­—æ®µã€é‡å¤å­—æ®µã€å¤šè¾“å‡ºç©ºå€¼æˆ–ç©ºè¡Œï¼›
# - è¾“å‡ºä¸­ä¸å¾—å‡ºç° Markdown åŒ…è£¹ï¼ˆå¦‚ ```ï¼‰æˆ–é¢å¤–è¯´æ˜æ–‡å­—ã€‚

# æ¨¡æ¿è¡¨å¤´æ˜ å°„ï¼š
# {state["headers_mapping"]}
# """ 
        system_prompt = f"""
ä½ æ˜¯ä¸€åä¸“ä¸šä¸”ä¸¥è°¨çš„ç»“æ„åŒ–æ•°æ®å¡«æŠ¥ä¸“å®¶ï¼Œå…·å¤‡é€»è¾‘æ¨ç†å’Œè®¡ç®—èƒ½åŠ›ã€‚

è®©æˆ‘ä»¬ä¸€æ­¥ä¸€æ­¥æ¥è§£å†³è¿™ä¸ªæ•°æ®è½¬æ¢é—®é¢˜ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
æ ¹æ®åŸå§‹æ•°æ®å’Œæ¨¡æ¿æ˜ å°„è§„åˆ™ï¼Œå°†æ•°æ®å‡†ç¡®è½¬æ¢ä¸ºç›®æ ‡ CSV æ ¼å¼ã€‚

ã€è¾“å…¥å†…å®¹ã€‘
1. æ¨¡æ¿è¡¨å¤´æ˜ å°„ï¼ˆJSON æ ¼å¼ï¼‰ï¼šæè¿°ç›®æ ‡è¡¨æ ¼æ¯ä¸€åˆ—çš„æ¥æºã€è®¡ç®—é€»è¾‘æˆ–æ¨ç†è§„åˆ™ï¼›
2. åŸå§‹æ•°æ®é›†ï¼šåŒ…æ‹¬è¡¨å¤´ç»“æ„çš„ JSON å’Œ CSV æ•°æ®å—ã€‚

ã€æ¨ç†æ­¥éª¤ã€‘
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è¿›è¡Œæ¨ç†ï¼Œå¹¶å±•ç¤ºæ¯ä¸€æ­¥çš„æ€è€ƒè¿‡ç¨‹ï¼š

æ­¥éª¤1ï¼šç†è§£æ˜ å°„è§„åˆ™
- é€ä¸€åˆ†ææ¯ä¸ªç›®æ ‡å­—æ®µçš„å®šä¹‰
- æ˜ç¡®æ•°æ®æ¥æºå’Œè½¬æ¢è§„åˆ™

æ­¥éª¤2ï¼šå®šä½åŸå§‹æ•°æ®
- åœ¨åŸå§‹æ•°æ®ä¸­æ‰¾åˆ°å¯¹åº”å­—æ®µ
- éªŒè¯æ•°æ®æ ¼å¼å’Œå®Œæ•´æ€§

æ­¥éª¤3ï¼šæ‰§è¡Œè½¬æ¢é€»è¾‘
- å¯¹äºè®¡ç®—å­—æ®µï¼šæ˜ç¡®å…¬å¼å¹¶é€æ­¥è®¡ç®—
- å¯¹äºæ¨ç†å­—æ®µï¼šå±•ç¤ºé€»è¾‘åˆ¤æ–­è¿‡ç¨‹
- å¯¹äºæ ¼å¼è½¬æ¢ï¼šè¯´æ˜è½¬æ¢è§„åˆ™

æ­¥éª¤4ï¼šè´¨é‡æ£€æŸ¥
- éªŒè¯æ¯ä¸ªå­—æ®µçš„åˆç†æ€§
- æ£€æŸ¥æ ¼å¼è§„èŒƒæ€§
- ç¡®è®¤å­—æ®µé¡ºåºæ­£ç¡®

ã€è¾“å‡ºæ ¼å¼ã€‘
è¯·æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¾“å‡ºï¼š

=== æ¨ç†è¿‡ç¨‹ ===
[å±•ç¤ºä½ çš„å®Œæ•´æ€è€ƒè¿‡ç¨‹ï¼ŒåŒ…æ‹¬æ¯ä¸ªå­—æ®µçš„åˆ†æã€å®šä½ã€è½¬æ¢å’ŒéªŒè¯]

=== æœ€ç»ˆç­”æ¡ˆ ===
[ä»…è¾“å‡ºçº¯å‡€çš„ CSV æ•°æ®è¡Œï¼Œä½¿ç”¨è‹±æ–‡é€—å·åˆ†éš”]

ã€è´¨é‡è¦æ±‚ã€‘
- æ¨ç†è¿‡ç¨‹å¿…é¡»è¯¦ç»†å±•ç¤ºæ¯ä¸ªæ­¥éª¤çš„æ€è€ƒ
- æœ€ç»ˆç­”æ¡ˆä»…åŒ…å«CSVæ•°æ®ï¼Œä¸å«ä»»ä½•å…¶ä»–å†…å®¹
- å­—æ®µé¡ºåºå¿…é¡»ä¸æ¨¡æ¿è¡¨å¤´æ˜ å°„å®Œå…¨ä¸€è‡´
- ä¸¥ç¦é—æ¼å­—æ®µã€é‡å¤å­—æ®µæˆ–è¾“å‡ºç©ºå€¼

æ¨¡æ¿è¡¨å¤´æ˜ å°„ï¼š
{state["headers_mapping"]}
"""

        print("ğŸ“‹ ç³»ç»Ÿæç¤ºå‡†å¤‡å®Œæˆ")
        print("ç³»ç»Ÿæç¤ºè¯ï¼š", system_prompt)
        
        def process_single_chunk(chunk_data):
            """å¤„ç†å•ä¸ªchunkçš„å‡½æ•°"""
            chunk, index = chunk_data
            try:
                user_input = f"""
                æ•°æ®çº§ï¼š
                {chunk}
                """             
                print("ç”¨æˆ·è¾“å…¥æç¤ºè¯", system_prompt)
                print(f"ğŸ¤– Processing chunk {index + 1}/{len(state['combined_data_array'])}...")
                response = invoke_model(
                    model_name="deepseek-ai/DeepSeek-V3", 
                    messages=[SystemMessage(content=system_prompt), HumanMessage(content=user_input)],
                    temperature=0.2
                )
                print(f"âœ… Completed chunk {index + 1}")
                return (index, response)
            except Exception as e:
                print(f"âŒ Error processing chunk {index + 1}: {e}")
                return (index, f"Error processing chunk {index + 1}: {e}")
        
        # Prepare chunk data with indices
        chunks_with_indices = [(chunk, i) for i, chunk in enumerate(state["combined_data_array"])]
        
        if not chunks_with_indices:
            print("âš ï¸ æ²¡æœ‰æ•°æ®å—éœ€è¦å¤„ç†")
            print("âœ… _generate_CSV_based_on_combined_data æ‰§è¡Œå®Œæˆ(æ— æ•°æ®)")
            print("=" * 50)
            return {"CSV_data": []}
        
        print(f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {len(chunks_with_indices)} ä¸ªæ•°æ®å—...")
        
        # Use ThreadPoolExecutor for concurrent processing
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        results = {}
        with ThreadPoolExecutor(max_workers=15) as executor:  # Limit to 5 concurrent requests
            # Submit all tasks
            future_to_index = {executor.submit(process_single_chunk, chunk_data): chunk_data[1] 
                              for chunk_data in chunks_with_indices}
            print(f"âœ… å·²æäº¤ {len(future_to_index)} ä¸ªå¹¶å‘ä»»åŠ¡")
            
            # Collect results as they complete
            completed_count = 0
            for future in as_completed(future_to_index):
                try:
                    index, response = future.result()
                    results[index] = response
                    completed_count += 1
                    print(f"âœ… å®Œæˆç¬¬ {completed_count}/{len(chunks_with_indices)} ä¸ªä»»åŠ¡")
                except Exception as e:
                    index = future_to_index[future]
                    print(f"âŒ ç¬¬ {index + 1} ä¸ªæ•°æ®å—å¤„ç†å¼‚å¸¸: {e}")
                    results[index] = f"æ•°æ®å— {index + 1} å¤„ç†å¼‚å¸¸: {e}"
        
        # Sort results by index to maintain order
        sorted_results = [results[i] for i in sorted(results.keys())]
        
        print(f"ğŸ‰ æˆåŠŸå¹¶å‘å¤„ç† {len(sorted_results)} ä¸ªæ•°æ®å—")
        
        # Save CSV data to output folder using helper function
        try:
            from utilities.file_process import save_csv_to_output
            saved_file_path = save_csv_to_output(sorted_results, state["session_id"])
            print(f"âœ… CSVæ•°æ®å·²ä¿å­˜åˆ°è¾“å‡ºæ–‡ä»¶å¤¹: {saved_file_path}")
        except Exception as e:
            print(f"âŒ ä¿å­˜CSVæ–‡ä»¶æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            print("âš ï¸ æ•°æ®ä»ä¿å­˜åœ¨å†…å­˜ä¸­ï¼Œå¯ç»§ç»­å¤„ç†")
        
        print("âœ… _generate_CSV_based_on_combined_data æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        print(f"ğŸ” ç”Ÿæˆçš„CSVæ•°æ®: {sorted_results}")
        return {
            "CSV_data": sorted_results
        }
    
    def _extract_empty_row_html(self, state: FilloutTableState) -> FilloutTableState:
        """æå–æ¨¡æ¿è¡¨æ ¼ä¸­çš„ç©ºè¡Œhtmlä»£ç """
        template_file_content = read_txt_file(state["template_file"])
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HTMLè¡¨æ ¼æ¨¡æ¿åˆ†æä¸“å®¶ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
ä»Excelè¡¨æ ¼çš„HTMLæ¨¡æ¿ä¸­æå–å‡ºè¡¨ç¤ºç©ºç™½æ•°æ®è¡Œçš„HTMLä»£ç ã€‚

ã€æå–è§„åˆ™ã€‘
1. è¯†åˆ«æ¨¡æ¿ä¸­ç”¨äºå¡«å†™æ•°æ®çš„ç©ºç™½è¡Œï¼ˆé€šå¸¸åŒ…å«<br/>æˆ–ç©ºç™½å†…å®¹ï¼‰,åªéœ€è¦è¯†åˆ«å‡ºä¸€ä¸ª
2. æ¸…ç†æ‰ä»»ä½•å·²å¡«å…¥çš„ç¤ºä¾‹æ•°æ®ï¼Œåªä¿ç•™ç©ºç™½è¡Œç»“æ„
3. ä¿æŒåŸå§‹HTMLæ ‡ç­¾ç»“æ„å’Œå±æ€§ä¸å˜
4. å¿½ç•¥è¡¨å¤´ã€æ ‡é¢˜è¡Œã€ç»“å°¾è¡Œç­‰éæ•°æ®è¡Œ

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä»…è¾“å‡ºçº¯HTMLä»£ç ï¼Œä¸è¦åŒ…è£¹åœ¨```html```ä¸­
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–å…¶ä»–æ–‡æœ¬
- ç¡®ä¿è¾“å‡ºçš„HTMLä»£ç æ ¼å¼æ­£ç¡®ä¸”å¯ç›´æ¥ä½¿ç”¨
- å¦‚æœæœ‰å¤šä¸ªç©ºç™½è¡Œåªéœ€è¦è¾“å‡ºä¸€ä¸ª

ã€ç¤ºä¾‹ã€‘
è¾“å…¥HTMLæ¨¡æ¿åŒ…å«ï¼š
<tr>
<td>1</td>
<td>å¼ ä¸‰</td>
<td>ç”·</td>
<td>25</td>
</tr>
<tr>
<td>2</td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
</tr>

åº”è¯¥è¾“å‡ºï¼š
<tr>
<td></td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
</tr>
æœ‰æ—¶è¾“å…¥çš„htmlæ¨¡æ¿ä¸­æ²¡æœ‰ç©ºç™½è¡Œï¼Œä½ éœ€è¦æ ¹æ®è¡¨å¤´æ¥æ„å»ºç©ºç™½è¡Œï¼Œè§„åˆ™éå¸¸ç®€å•ï¼Œåªéœ€è¦æŠŠè¡¨å¤´ä¸­çš„æ¯ä¸ªå­—æ®µéƒ½å¡«å……ä¸º<br/>å³å¯
        """
        response = invoke_model(
            model_name="deepseek-ai/DeepSeek-V3",
            messages=[SystemMessage(content=system_prompt), HumanMessage(content=template_file_content)]
        )
        return {"empty_row_html": response}
        

    def _extract_headers_html(self, state: FilloutTableState) -> FilloutTableState:
        """æå–å‡ºhtmlæ¨¡æ¿è¡¨æ ¼çš„è¡¨å¤´htmlä»£ç """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HTMLè¡¨æ ¼æ¨¡æ¿åˆ†æä¸“å®¶ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
ä»Excelè¡¨æ ¼çš„HTMLæ¨¡æ¿ä¸­æå–å‡ºè¡¨å¤´éƒ¨åˆ†çš„HTMLä»£ç ï¼ˆä»å¼€å§‹åˆ°ç¬¬ä¸€ä¸ªç©ºç™½æ•°æ®è¡Œä¹‹å‰çš„æ‰€æœ‰å†…å®¹ï¼‰ã€‚

ã€æå–è§„åˆ™ã€‘
1. åŒ…å«HTMLæ–‡æ¡£çš„å¼€å§‹æ ‡ç­¾ï¼ˆ<html><body><table>ï¼‰
2. åŒ…å«æ‰€æœ‰åˆ—ç»„å®šä¹‰ï¼ˆ<colgroup>ï¼‰
3. åŒ…å«è¡¨æ ¼æ ‡é¢˜è¡Œï¼ˆé€šå¸¸ä½¿ç”¨colspançš„æ ‡é¢˜ï¼‰
4. åŒ…å«è¡¨æ ¼åˆ—å¤´è¡Œï¼ˆå®šä¹‰å„åˆ—åç§°ï¼‰
5. åœæ­¢åœ¨ç¬¬ä¸€ä¸ªç©ºç™½æ•°æ®è¡Œä¹‹å‰
6. ä¿æŒåŸå§‹HTMLæ ‡ç­¾ç»“æ„å’Œå±æ€§ä¸å˜

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä»…è¾“å‡ºçº¯HTMLä»£ç ï¼Œä¸è¦åŒ…è£¹åœ¨```html```ä¸­
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–å…¶ä»–æ–‡æœ¬
- ç¡®ä¿è¾“å‡ºçš„HTMLä»£ç æ ¼å¼æ­£ç¡®ä¸”å¯ç›´æ¥ä½¿ç”¨
- ä¸€å®šä¸è¦è‡ªåŠ¨è¡¥å…¨ï¼Œä¾‹å¦‚<table>æ ‡ç­¾ï¼Œä¸è¦åŠ ä¸Š</table>æ ‡ç­¾

ã€ç¤ºä¾‹ã€‘
è¾“å…¥HTMLæ¨¡æ¿åŒ…å«ï¼š
<html><body><table>
<colgroup></colgroup>
<colgroup></colgroup>
<colgroup></colgroup>
<tr>
<td colspan="3">å‘˜å·¥ä¿¡æ¯è¡¨</td>
</tr>
<tr>
<td>å§“å</td>
<td>å¹´é¾„</td>
<td>éƒ¨é—¨</td>
</tr>
<tr>
<td><br/></td>
<td><br/></td>
<td><br/></td>
</tr>
<tr>
<td colspan="3">åˆ¶è¡¨äººï¼šXXX</td>
</tr>
</table></body></html>

åº”è¯¥è¾“å‡ºï¼š
<html><body><table>
<colgroup></colgroup>
<colgroup></colgroup>
<colgroup></colgroup>
<tr>
<td colspan="3">å‘˜å·¥ä¿¡æ¯è¡¨</td>
</tr>
<tr>
<td>å§“å</td>
<td>å¹´é¾„</td>
<td>éƒ¨é—¨</td>
</tr>
        """
        template_file_content = read_txt_file(state["template_file"])
        response = invoke_model(
            model_name="deepseek-ai/DeepSeek-V3",
            messages=[SystemMessage(content=system_prompt), HumanMessage(content=template_file_content)]
        )
        return {"headers_html": response}
    
    def _extract_footer_html(self, state: FilloutTableState) -> FilloutTableState:
        """æå–å‡ºhtmlæ¨¡æ¿è¡¨æ ¼çš„ç»“å°¾htmlä»£ç """
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HTMLè¡¨æ ¼æ¨¡æ¿åˆ†æä¸“å®¶ã€‚

ã€ä»»åŠ¡ç›®æ ‡ã€‘
ä»Excelè¡¨æ ¼çš„HTMLæ¨¡æ¿ä¸­æå–å‡ºé¡µè„šéƒ¨åˆ†çš„HTMLä»£ç ï¼ˆä»æœ€åä¸€ä¸ªæ•°æ®è¡Œä¹‹ååˆ°HTMLæ–‡æ¡£ç»“æŸçš„æ‰€æœ‰å†…å®¹ï¼‰ã€‚

ã€æå–è§„åˆ™ã€‘
1. è¯†åˆ«æœ€åä¸€ä¸ªæ•°æ®è¡Œï¼ˆç©ºç™½è¡Œï¼‰çš„ä½ç½®
2. æå–è¯¥è¡Œä¹‹åçš„æ‰€æœ‰å†…å®¹
3. é€šå¸¸åŒ…å«ç­¾åè¡Œã€ç»Ÿè®¡è¡Œã€å®¡æ ¸ä¿¡æ¯ç­‰
4. åŒ…å«HTMLæ–‡æ¡£çš„ç»“æŸæ ‡ç­¾ï¼ˆ</table></body></html>ï¼‰
5. ä¿æŒåŸå§‹HTMLæ ‡ç­¾ç»“æ„å’Œå±æ€§ä¸å˜

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä»…è¾“å‡ºçº¯HTMLä»£ç ï¼Œä¸è¦åŒ…è£¹åœ¨```html```ä¸­
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–å…¶ä»–æ–‡æœ¬
- ç¡®ä¿è¾“å‡ºçš„HTMLä»£ç æ ¼å¼æ­£ç¡®ä¸”å¯ç›´æ¥ä½¿ç”¨

ã€ç¤ºä¾‹ã€‘
è¾“å…¥HTMLæ¨¡æ¿åŒ…å«ï¼š
<html><body><table>
<colgroup></colgroup>
<colgroup></colgroup>
<colgroup></colgroup>
<tr>
<td colspan="3">å‘˜å·¥ä¿¡æ¯è¡¨</td>
</tr>
<tr>
<td>å§“å</td>
<td>å¹´é¾„</td>
<td>éƒ¨é—¨</td>
</tr>
<tr>
<td><br/></td>
<td><br/></td>
<td><br/></td>
</tr>
<tr>
<td colspan="3">åˆ¶è¡¨äººï¼šXXXå®¡æ ¸äººï¼šYYY</td>
</tr>
</table></body></html>

åº”è¯¥è¾“å‡ºï¼š
<tr>
<td colspan="3">åˆ¶è¡¨äººï¼šXXXå®¡æ ¸äººï¼šYYY</td>
</tr>
</table></body></html>
        """
        template_file_content = read_txt_file(state["template_file"])
        response = invoke_model(
            model_name="deepseek-ai/DeepSeek-V3",
            messages=[SystemMessage(content=system_prompt), HumanMessage(content=template_file_content)]
        )
        return {"footer_html": response}
    
    def _shield_for_transform_data_to_html(self, state: FilloutTableState) -> FilloutTableState:
        """å±è”½transform_data_to_htmlçš„æ‰§è¡Œ"""
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ: _shield_for_transform_data_to_html")
        print("=" * 50)
        print("æ‘˜å–åˆ°çš„è¡¨å¤´ï¼š", state["headers_html"])
        print("æ‘˜å–åˆ°çš„è¡¨å°¾ï¼š", state["footer_html"])
        print("æ‘˜å–åˆ°çš„ç©ºç™½è¡Œï¼š", state["empty_row_html"])
        return state
    

    def _transform_data_to_html(self, state: FilloutTableState) -> FilloutTableState:
        """å°†æ•°æ®è½¬æ¢ä¸ºhtmlä»£ç """
        # return state
        system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„HTMLè¡¨æ ¼æ•°æ®å¤„ç†å’Œç¾åŒ–ä¸“å®¶ã€‚ä½ éœ€è¦å°†CSVæ•°æ®å¡«å…¥HTMLæ¨¡æ¿ä¸­ï¼Œå¹¶ä¸ºè¡¨æ ¼æ·»åŠ ç°ä»£åŒ–çš„CSSæ ·å¼è£…é¥°ï¼Œä½¿å…¶ç¾è§‚ä¸“ä¸šã€‚

ã€æ ¸å¿ƒä»»åŠ¡ã€‘
1. å°†æä¾›çš„CSVæ•°æ®å‡†ç¡®å¡«å…¥HTMLæ¨¡æ¿
2. ä¸ºè¡¨æ ¼æ·»åŠ ç°ä»£åŒ–çš„CSSæ ·å¼ï¼Œæå‡è§†è§‰æ•ˆæœ

ã€ç¾åŒ–è®¾è®¡åŸåˆ™ã€‘
- ç®€æ´ç°ä»£ï¼šé‡‡ç”¨ç®€çº¦è®¾è®¡é£æ ¼ï¼Œé¿å…è¿‡åº¦è£…é¥°
- æ¸…æ™°æ˜“è¯»ï¼šç¡®ä¿æ–‡å­—æ¸…æ™°ï¼Œå¯¹æ¯”åº¦è‰¯å¥½
- ä¸“ä¸šç¾è§‚ï¼šé€‚åˆæ­£å¼åœºåˆçš„è¡¨æ ¼æ ·å¼
- å“åº”å¼å‹å¥½ï¼šé€‚é…ä¸åŒå±å¹•å°ºå¯¸

ã€CSSæ ·å¼è¦æ±‚ã€‘
è¯·ä¸ºè¡¨æ ¼æ·»åŠ ä»¥ä¸‹æ ·å¼ç‰¹æ€§ï¼š
1. **è¾¹æ¡†è®¾è®¡**: ç»†çº¿è¾¹æ¡†ï¼Œç»Ÿä¸€é¢œè‰²ï¼Œåœ†è§’è®¾è®¡
2. **é—´è·ä¼˜åŒ–**: åˆé€‚çš„å†…è¾¹è·(padding)å’Œè¡Œé«˜(line-height)
3. **å­—ä½“è®¾ç½®**: æ¸…æ™°æ˜“è¯»çš„å­—ä½“æ—ï¼Œåˆé€‚çš„å­—ä½“å¤§å°
4. **é¢œè‰²æ­é…**: 
   - è¡¨å¤´ï¼šä¼˜é›…çš„èƒŒæ™¯è‰²(å¦‚#f8f9faæˆ–#e9ecef)
   - æ•°æ®è¡Œï¼šäº¤æ›¿è¡Œé¢œè‰²æˆ–ç»Ÿä¸€æµ…è‰²èƒŒæ™¯
   - æ–‡å­—ï¼šæ·±è‰²æ–‡å­—ç¡®ä¿å¯è¯»æ€§
5. **å¯¹é½æ–¹å¼**: æ–‡æœ¬å±…ä¸­æˆ–å·¦å¯¹é½ï¼Œä¿æŒä¸€è‡´æ€§
6. **æ‚¬åœæ•ˆæœ**: é¼ æ ‡æ‚¬åœæ—¶çš„é«˜äº®æ•ˆæœ
7. **é˜´å½±æ•ˆæœ**: è½»å¾®çš„box-shadowå¢åŠ ç«‹ä½“æ„Ÿ
8. **å®½åº¦æ§åˆ¶**: è¡¨æ ¼å®½åº¦è‡ªé€‚åº”ï¼Œåˆ—å®½å‡åŒ€åˆ†å¸ƒ

ã€è¾“å‡ºè¦æ±‚ã€‘
- ä»…è¾“å‡ºå®Œæ•´çš„HTMLä»£ç ï¼ŒåŒ…å«å†…è”CSSæ ·å¼
- ä¸è¦è¾“å‡ºä»»ä½•è§£é‡Šã€æ³¨é‡Šæˆ–å…¶ä»–æ–‡æœ¬
- ä¸è¦åŒ…è£¹åœ¨```html```ä¸­
- CSSæ ·å¼ä½¿ç”¨å†…è”styleæˆ–<style>æ ‡ç­¾
- ç¡®ä¿æ•°æ®å¡«å…¥å‡†ç¡®æ— è¯¯

ã€ç¤ºä¾‹ã€‘
è¾“å…¥æ•°æ®ï¼š1,å¼ ä¸‰,ç”·,æ±‰æ—,123456,1990-01-01,æ— 
è¾“å…¥æ¨¡æ¿ï¼š
<tr>
<td>1</td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
<td><br/></td>
</tr>

è¾“å‡ºç»“æœï¼š
<tr style="background-color: #ffffff; transition: background-color 0.3s ease;">
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">1</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">å¼ ä¸‰</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">ç”·</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">æ±‰æ—</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">123456</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">1990-01-01</td>
<td style="padding: 12px 15px; border: 1px solid #ddd; text-align: center; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-size: 14px; color: #333;">æ— </td>
</tr>

ã€ç‰¹åˆ«æ³¨æ„ã€‘
- ä¿æŒæ•°æ®çš„å‡†ç¡®æ€§ï¼Œä¸å¾—ä¿®æ”¹æˆ–é—æ¼ä»»ä½•æ•°æ®
- CSSæ ·å¼è¦ç»Ÿä¸€ä¸€è‡´ï¼Œæ‰€æœ‰å•å…ƒæ ¼ä½¿ç”¨ç›¸åŒçš„æ ·å¼
- ç¡®ä¿è¾“å‡ºçš„HTMLåœ¨æµè§ˆå™¨ä¸­èƒ½æ­£ç¡®æ˜¾ç¤ºå’Œç¾è§‚å‘ˆç°
        """
        
        try:
            # Read CSV data
            csv_file_path = f"conversations/{state['session_id']}/CSV_files/synthesized_table_with_only_data.csv"
            print(f"ğŸ“„ è¯»å–CSVæ–‡ä»¶: {csv_file_path}")
            
            with open(csv_file_path, 'r', encoding='utf-8') as file:
                csv_data = file.read().strip().split('\n')
            
            print(f"ğŸ“Š CSVæ•°æ®è¡Œæ•°: {len(csv_data)}")
            
            # Split into specified number of chunks for parallel processing
            num_chunks = 15  # Number of parallel tasks to create
            total_rows = len(csv_data)
            
            # Calculate chunk size based on total rows and desired number of chunks
            chunk_size = max(1, total_rows // num_chunks)
            actual_num_chunks = min(num_chunks, total_rows)  # Don't create more chunks than rows
            
            chunks = [csv_data[i:i + chunk_size] for i in range(0, total_rows, chunk_size)]
            print(f"ğŸ“¦ åˆ†å‰²ä¸º {len(chunks)} ä¸ªæ•°æ®å—ï¼Œæ€»å…± {total_rows} è¡Œ")
            print(f"ğŸš€ å°†åˆ›å»º {len(chunks)} ä¸ªå¹¶è¡ŒLLMè°ƒç”¨ä»»åŠ¡ï¼Œæ¯å—çº¦ {chunk_size} è¡Œ")
            
            # Get empty row HTML template from state
            empty_row_html = state.get("empty_row_html", "")
            if not empty_row_html:
                print("âš ï¸ æœªæ‰¾åˆ°ç©ºè¡ŒHTMLæ¨¡æ¿")
                return {"filled_row": ""}
            
            def process_single_chunk(chunk_data):
                """å¤„ç†å•ä¸ªchunkçš„å‡½æ•°"""
                chunk, index = chunk_data
                try:
                    # Join chunk data with newlines
                    chunk_csv = '\n'.join(chunk)
                    
                    user_input = f"""
                    ä»£å¡«æ•°æ®ï¼š
                    {chunk_csv}
                    htmlæ¨¡æ¿ï¼š
                    {empty_row_html}
                    """
                    
                    print(f"ğŸ¤– Processing chunk {index + 1}/{len(chunks)}...")
                    response = invoke_model(
                        model_name="deepseek-ai/DeepSeek-V3", 
                        messages=[SystemMessage(content=system_prompt), HumanMessage(content=user_input)],
                        temperature=0.2
                    )
                    print(f"âœ… Completed chunk {index + 1}")
                    return (index, response)
                except Exception as e:
                    print(f"âŒ Error processing chunk {index + 1}: {e}")
                    return (index, f"Error processing chunk {index + 1}: {e}")
            
            # Prepare chunk data with indices
            chunks_with_indices = [(chunk, i) for i, chunk in enumerate(chunks)]
            
            if not chunks_with_indices:
                print("âš ï¸ æ²¡æœ‰æ•°æ®å—éœ€è¦å¤„ç†")
                return {"filled_row": ""}
            
            print(f"ğŸš€ å¼€å§‹å¹¶å‘å¤„ç† {len(chunks_with_indices)} ä¸ªæ•°æ®å—...")
            
            # Use ThreadPoolExecutor for concurrent processing
            from concurrent.futures import ThreadPoolExecutor, as_completed
            
            results = {}
            with ThreadPoolExecutor(max_workers=15) as executor:
                # Submit all tasks
                future_to_index = {executor.submit(process_single_chunk, chunk_data): chunk_data[1] 
                                  for chunk_data in chunks_with_indices}
                print(f"âœ… å·²æäº¤ {len(future_to_index)} ä¸ªå¹¶å‘ä»»åŠ¡")
                
                # Collect results as they complete
                completed_count = 0
                for future in as_completed(future_to_index):
                    try:
                        index, response = future.result()
                        results[index] = response
                        completed_count += 1
                        print(f"âœ… å®Œæˆç¬¬ {completed_count}/{len(chunks_with_indices)} ä¸ªä»»åŠ¡")
                    except Exception as e:
                        index = future_to_index[future]
                        print(f"âŒ ç¬¬ {index + 1} ä¸ªæ•°æ®å—å¤„ç†å¼‚å¸¸: {e}")
                        results[index] = f"æ•°æ®å— {index + 1} å¤„ç†å¼‚å¸¸: {e}"
            
            # Sort results by index and combine into single HTML string
            sorted_results = [results[i] for i in sorted(results.keys())]
            combined_html = '\n'.join(sorted_results)
            
            print(f"ğŸ‰ æˆåŠŸå¹¶å‘å¤„ç† {len(sorted_results)} ä¸ªæ•°æ®å—")
            print(f"ğŸ“„ åˆå¹¶åHTMLé•¿åº¦: {len(combined_html)} å­—ç¬¦")
            
            print("âœ… _transform_data_to_html æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            
            return {"filled_row": combined_html}
            
        except Exception as e:
            print(f"âŒ _transform_data_to_html æ‰§è¡Œå¤±è´¥: {e}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return {"filled_row": ""}
    
    def _combine_html_tables(self, state: FilloutTableState) -> FilloutTableState:
        """å°†è¡¨å¤´ï¼Œæ•°æ®ï¼Œè¡¨å°¾htmlæ•´åˆåœ¨ä¸€èµ·ï¼Œå¹¶æ·»åŠ å…¨å±€ç¾åŒ–æ ·å¼"""
        print("\nğŸ”„ å¼€å§‹æ‰§è¡Œ: _combine_html_tables")
        print("=" * 50)
        
        # è·å–å„éƒ¨åˆ†HTML
        headers_html = state.get("headers_html", "")
        data_html = state.get("filled_row", "")
        footer_html = state.get("footer_html", "")
        
        # åˆ›å»ºå®Œæ•´çš„HTMLæ–‡æ¡£ï¼ŒåŒ…å«å…¨å±€æ ·å¼
        complete_html = f"""<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>è¡¨æ ¼æŠ¥å‘Š</title>
    <style>
        body {{
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f5f5f5;
            line-height: 1.6;
        }}
        
        .table-container {{
            background-color: white;
            border-radius: 8px;
            box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
            overflow: hidden;
            margin: 0 auto;
            max-width: 1200px;
            padding: 20px;
        }}
        
        table {{
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            background-color: white;
        }}
        
        /* è¡¨å¤´æ ·å¼ */
        table tr:first-child td {{
            background-color: #2c3e50 !important;
            color: white !important;
            font-weight: bold;
            text-align: center;
            padding: 15px 12px;
            font-size: 16px;
        }}
        
        /* åˆ—å¤´æ ·å¼ */
        table tr:nth-child(2) td,
        table tr:nth-child(3) td {{
            background-color: #34495e !important;
            color: white !important;
            font-weight: 600;
            text-align: center;
            padding: 12px 10px;
            font-size: 14px;
        }}
        
        /* æ•°æ®è¡Œæ ·å¼ */
        table tr:not(:first-child):not(:nth-child(2)):not(:nth-child(3)):not(:last-child) {{
            background-color: #ffffff;
        }}
        
        table tr:not(:first-child):not(:nth-child(2)):not(:nth-child(3)):not(:last-child):nth-child(even) {{
            background-color: #f8f9fa;
        }}
        
        /* æ•°æ®å•å…ƒæ ¼æ ·å¼ */
        table tr:not(:first-child):not(:nth-child(2)):not(:nth-child(3)) td {{
            padding: 12px 15px;
            border: 1px solid #dee2e6;
            text-align: center;
            font-size: 14px;
            color: #333;
            transition: background-color 0.3s ease;
        }}
        
        /* æ‚¬åœæ•ˆæœ */
        table tr:not(:first-child):not(:nth-child(2)):not(:nth-child(3)):hover {{
            background-color: #e3f2fd !important;
            transform: translateY(-1px);
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }}
        
        /* é¡µè„šæ ·å¼ */
        table tr:last-child td {{
            background-color: #ecf0f1 !important;
            color: #2c3e50 !important;
            font-weight: 500;
            padding: 15px 12px;
            font-size: 13px;
            border-top: 2px solid #bdc3c7;
        }}
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 768px) {{
            .table-container {{
                padding: 10px;
                margin: 10px;
            }}
            
            table td {{
                padding: 8px 6px;
                font-size: 12px;
            }}
            
            table tr:first-child td {{
                font-size: 14px;
            }}
        }}
        
        /* æ‰“å°æ ·å¼ */
        @media print {{
            body {{
                background-color: white;
                padding: 0;
            }}
            
            .table-container {{
                box-shadow: none;
                border: 1px solid #ccc;
            }}
        }}
    </style>
</head>
<body>
    <div class="table-container">
        {headers_html}
        {data_html}
        {footer_html}
    </div>
</body>
</html>"""
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        output_path = f"conversations/{state['session_id']}/output/combined_html.html"
        with open(output_path, "w", encoding="utf-8") as file:
            file.write(complete_html)
        
        print(f"âœ… ç¾åŒ–è¡¨æ ¼å·²ä¿å­˜åˆ°: {output_path}")
        print("âœ… _combine_html_tables æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {"combined_html": complete_html}
    
    def run_fillout_table_agent(self, session_id: str,
                                template_file: str,
                                data_file_path: list[str],
                                headers_mapping: dict[str, str]
                                ) -> None:
        """This function will run the fillout table agent using invoke method with manual debug printing"""
        print("\nğŸš€ å¯åŠ¨ FilloutTableAgent")
        print("=" * 60)
        
        initial_state = self.create_initialize_state(
            session_id = session_id,
            template_file = template_file,
            data_file_path = data_file_path,
            headers_mapping=headers_mapping
        )

        config = {"configurable": {"thread_id": session_id}}
        
        print(f"ğŸ“‹ åˆå§‹çŠ¶æ€åˆ›å»ºå®Œæˆï¼Œä¼šè¯ID: {session_id}")
        print(f"ğŸ“„ æ¨¡æ¿æ–‡ä»¶: {initial_state['template_file']}")
        print(f"ğŸ“Š æ•°æ®æ–‡ä»¶æ•°é‡: {len(initial_state['data_file_path'])}")

        print("-" * 60)

        while True:
            try:
                print(f"\nğŸ”„ æ‰§è¡ŒçŠ¶æ€å›¾ï¼Œå½“å‰ä¼šè¯ID: {session_id}")
                print("-" * 50)
                
                final_state = self.graph.invoke(initial_state, config=config)
                
                if "__interrupt__" in final_state:
                    interrupt_value = final_state["__interrupt__"][0].value
                    print(f"ğŸ’¬ æ™ºèƒ½ä½“: {interrupt_value}")
                    user_response = input("ğŸ‘¤ è¯·è¾“å…¥æ‚¨çš„å›å¤: ")
                    initial_state = Command(resume=user_response)
                    continue
                
                print("\nâœ… FilloutTableAgentæ‰§è¡Œå®Œæ¯•")
                print("=" * 60)
                
                # Print final results
                if "filled_row" in final_state and final_state["filled_row"]:
                    print(f"ğŸ“Š æœ€ç»ˆç»“æœå·²ç”Ÿæˆ")
                    if len(str(final_state["filled_row"])) > 500:
                        print(f"ğŸ“„ å†…å®¹é•¿åº¦: {len(str(final_state['filled_row']))} å­—ç¬¦")
                    else:
                        print(f"ğŸ“„ å†…å®¹: {final_state['filled_row']}")
                        
                if "messages" in final_state and final_state["messages"]:
                    latest_message = final_state["messages"][-1]
                    if hasattr(latest_message, 'content'):
                        print(f"ğŸ’¬ æœ€ç»ˆæ¶ˆæ¯: {latest_message.content}")
                        
                break
                
            except Exception as e:
                print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
                print(f"é”™è¯¯ç±»å‹: {type(e).__name__}")
                import traceback
                print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                print("-" * 50)
                break
    


if __name__ == "__main__":
    # fillout_table_agent = FilloutTableAgent()
    # fillout_table_agent.run_fillout_table_agent( session_id = "1")
    # file_content = retrieve_file_content(session_id= "1", file_paths = [r"D:\asianInfo\ExcelAssist\ç‡•äº‘æ‘æµ‹è¯•æ ·ä¾‹\ç‡•äº‘æ‘æ®‹ç–¾äººè¡¥è´´\å¾…å¡«è¡¨\ç‡•äº‘æ‘æ®‹ç–¾äººè¡¥è´´ç”³é¢†ç™»è®°.xlsx"])

    # file_list = [r"D:\asianInfo\æ•°æ®\æ–°æ§æ‘\7.2æ¥é¾™é•‡é™„ä»¶4.xlsx", r"D:\asianInfo\æ•°æ®\æ–°æ§æ‘\10.24æ¥é¾™é•‡é™„ä»¶4ï¼šè„±è´«äººå£å°é¢è´·æ¬¾è´´æ¯å‘æ”¾æ˜ç»†è¡¨.xlsx", r"D:\asianInfo\æ•°æ®\æ–°æ§æ‘\12.3é™„ä»¶4ï¼šè„±è´«äººå£å°é¢è´·æ¬¾è´´æ¯ç”³æŠ¥æ±‡æ€»è¡¨.xlsx"]
    # fillout_table_agent = FilloutTableAgent()
    # combined_data = fillout_table_agent._combine_data_split_into_chunks(file_list)
    # print(combined_data)
    fillout_table_agent = FilloutTableAgent()
    fillout_table_agent.run_fillout_table_agent(session_id = "1",
                                                template_file = r"D:\asianInfo\ExcelAssist\conversations\1\user_uploaded_files\template\ç‡•äº‘æ‘æ®‹ç–¾äººè¡¥è´´ç”³é¢†ç™»è®°.txt",
                                                data_file_path = [r"D:\asianInfo\ExcelAssist\files\table_files\original\ç‡•äº‘æ‘æ®‹ç–¾äººåå•.xlsx"],
                                                headers_mapping={
  "è¡¨æ ¼ç»“æ„": {
    "ç‡•äº‘æ‘æ®‹ç–¾äººè¡¥è´´ç”³é¢†ç™»è®°": {
      "åºå·": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: åºå·"],
      "å§“å": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: å§“å"],
      "æ®‹ç–¾ç±»åˆ«": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: æ®‹ç–¾ç±»åˆ«"],
      "ç›‘æŠ¤äººå§“å": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: ç›‘æŠ¤äººå§“å"],
      "æ®‹ç–¾è¯å·": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: æ®‹ç–¾è¯å·"],
      "åœ°å€": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: åœ°å€"],
      "è”ç³»ç”µè¯": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: è”ç³»ç”µè¯"],
      "è¡¥è´´é‡‘é¢": [
        "æ¨ç†è§„åˆ™: æ ¹æ®é‡åº†å¸‚æ®‹ç–¾äººè¡¥è´´.txtä¸­çš„è¡¥è´´æ ‡å‡†è®¡ç®—",
        "1. å›°éš¾æ®‹ç–¾äººç”Ÿæ´»è¡¥è´´: æ¯äººæ¯æœˆ90å…ƒï¼ˆé€‚ç”¨äºä½ä¿å®¶åº­ä¸­çš„å„ç±»æ®‹ç–¾äººï¼‰",
        "2. é‡åº¦æ®‹ç–¾äººæŠ¤ç†è¡¥è´´: ä¸€çº§æ¯äººæ¯æœˆ100å…ƒï¼ŒäºŒçº§æ¯äººæ¯æœˆ90å…ƒ",
        "3. å…·ä½“è®¡ç®—é€»è¾‘:",
        "   - é¦–å…ˆéœ€è¦ç¡®è®¤æ®‹ç–¾äººæ˜¯å¦ä¸ºä½ä¿å®¶åº­ï¼ˆå½“å‰æ•°æ®ä¸­æ— æ­¤ä¿¡æ¯ï¼Œéœ€è¡¥å……ï¼‰",
        "   - è‹¥ä¸ºä½ä¿å®¶åº­ï¼Œåˆ™äº«å—å›°éš¾æ®‹ç–¾äººç”Ÿæ´»è¡¥è´´90å…ƒ",
        "   - è‹¥æ®‹ç–¾ç±»åˆ«ä¸º'ç²¾ç¥'æˆ–'æ™ºåŠ›'ä¸”æ®‹ç–¾è¯å·ç¬¬äºŒä½ä¸º'1'ï¼ˆä¸€çº§ï¼‰åˆ™é¢å¤–äº«å—100å…ƒæŠ¤ç†è¡¥è´´",
        "   - è‹¥æ®‹ç–¾ç±»åˆ«ä¸º'ç²¾ç¥'æˆ–'æ™ºåŠ›'ä¸”æ®‹ç–¾è¯å·ç¬¬äºŒä½ä¸º'2'ï¼ˆäºŒçº§ï¼‰åˆ™é¢å¤–äº«å—90å…ƒæŠ¤ç†è¡¥è´´",
        "   - å…¶ä»–æƒ…å†µä»…äº«å—åŸºç¡€è¡¥è´´ï¼ˆè‹¥æœ‰ï¼‰"
      ],
      "å¤‡æ³¨": ["ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt: å¤‡æ³¨"]
    }
  },
  "è¡¨æ ¼æ€»ç»“": "è¯¥è¡¨æ ¼ç”¨äºè®°å½•ç‡•äº‘æ‘æ®‹ç–¾äººè¡¥è´´ç”³é¢†ä¿¡æ¯ï¼Œå¤§éƒ¨åˆ†å­—æ®µå¯ç›´æ¥ä»'ç‡•äº‘æ‘æ®‹ç–¾äººåå•.txt'ä¸­è·å–ã€‚è¡¥è´´é‡‘é¢å­—æ®µéœ€è¦æ ¹æ®é‡åº†å¸‚æ®‹ç–¾äººè¡¥è´´æ”¿ç­–è¿›è¡Œè®¡ç®—ï¼Œå½“å‰ç¼ºå°‘ä½ä¿å®¶åº­ä¿¡æ¯ï¼Œéœ€è¦è¡¥å……è¯¥ä¿¡æ¯æ‰èƒ½å‡†ç¡®è®¡ç®—è¡¥è´´é‡‘é¢ã€‚"
})