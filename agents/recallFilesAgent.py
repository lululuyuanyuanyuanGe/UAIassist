import sys
from pathlib import Path

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, TypedDict, Annotated
from utilities.file_process import fetch_related_files_content, extract_file_from_recall
from utilities.modelRelated import invoke_model, invoke_model_with_tools

import json
import tempfile
import hashlib
import time
# Create an interactive chatbox using gradio
import re

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.messages import AIMessage, BaseMessage, SystemMessage, HumanMessage
from langchain_core.tools import tool

from agents.processUserInput import ProcessUserInputAgent

# Define tool as standalone function (not class method)
@tool
def request_user_clarification(question: str) -> str:
    """
    è¿™ä¸ªå‡½æ•°ç”¨äºå‘ç”¨æˆ·è¯·æ±‚æ¾„æ¸…ï¼Œä¾‹å¦‚è¯¢é—®ç”¨æˆ·å¬å›çš„æ–‡ä»¶æ­£ç¡®ä¸æ­£ç¡®ï¼Œæ˜¯å¦éœ€è¦é‡æ–°å¬å›ï¼Œ
    æˆ–è€…è¡¥å……å¬å›ï¼Œä¹Ÿå¯è¯¢é—®ç”¨æˆ·å½±å°„å…³ç³»æ˜¯å¦æ­£ç¡®ï¼Œæˆ–è€…æœ‰äº›æ˜ å°„å®åœ¨æ— æ³•ç»“å±€æ—¶å¯å‘ç”¨æˆ·è¯¢é—®

    å‚æ•°ï¼šquestion: ä½ çš„é—®é¢˜
    è¿”å›ï¼šç”¨æˆ·å›ç­”
    """
    try:
        print("request_user_clarification è¢«è°ƒç”¨=========================================\n", question)
        process_user_input_agent = ProcessUserInputAgent()
        response = process_user_input_agent.run_process_user_input_agent(previous_AI_messages=AIMessage(content=question))
        
        # Extract the summary message from response
        summary_message = response[0]
        print("request_user_clarification è°ƒç”¨æ¨¡å‹çš„è¾“å…¥: \n" + summary_message)
        summary_message = json.loads(summary_message)
        print("request_user_clarification è°ƒç”¨æ¨¡å‹çš„è¾“å…¥ç±»å‹: \n" + str(type(summary_message)))
        summary_message = summary_message["summary"]
        print("request_user_clarification è°ƒç”¨æ¨¡å‹çš„è¾“å‡º: \n" + summary_message)
        return summary_message

    except Exception as e:
        print(f"âŒ ç”¨æˆ·æ¾„æ¸…è¯·æ±‚å¤±è´¥: {e}")
        return f"æ— æ³•è·å–ç”¨æˆ·å›å¤: {str(e)}"


class RecallFilesState(TypedDict):
    messages: Annotated[list[BaseMessage], add_messages]
    chat_history: list[str]
    related_files_str: str
    related_files: list[str]
    classified_files: dict[str, list[str]]
    headers_mapping: dict[str, str]
    template_structure: str
    headers_mapping_: dict[any, any]
    file_content: str # æŠŠæ–‡ä»¶æ‘˜è¦é‡Œé¢çš„ç›¸å…³æ‘å­çš„æ–‡ä»¶å…¨éƒ¨æå–å‡ºæ¥ï¼Œå¹¶æŒ‰ç…§è¡¨æ ¼ï¼Œæ¨¡æ¿è¿›è¡Œåˆ†ç±»
    document_files_content: str # æŠŠæ–‡ä»¶æ‘˜è¦é‡Œé¢çš„ç›¸å…³æ‘å­çš„æ–‡ä»¶å…¨éƒ¨æå–å‡ºæ¥ï¼Œå¹¶æŒ‰ç…§è¡¨æ ¼ï¼Œæ¨¡æ¿è¿›è¡Œåˆ†ç±»


class RecallFilesAgent:
    def __init__(self):
        self.tools = [request_user_clarification]  # Reference the standalone function
        self.graph = self._build_graph()
        self.location: str # æ‘å­åå­—
        self.files_under_location: str # æ‘å­ä¸‹çš„æ–‡ä»¶
        self.related_files_classified: dict

    def _build_graph(self):
        graph = StateGraph(RecallFilesState)
        graph.add_node("recall_relative_files", self._recall_relative_files)
        graph.add_node("determine_the_mapping_of_headers", self._determine_the_mapping_of_headers)
        graph.add_node("request_user_clarification", ToolNode(self.tools))

        graph.add_edge(START, "recall_relative_files")
        graph.add_conditional_edges("recall_relative_files", self._route_after_recall_relative_files)
        graph.add_edge("request_user_clarification", "recall_relative_files")
        graph.add_edge("determine_the_mapping_of_headers", END)
        return graph.compile(checkpointer = MemorySaver())

    def _create_initial_state(self, template_structure: str) -> RecallFilesState:

        def extract_summary_for_each_file(file_content: dict) -> str:
            """æå–æ–‡ä»¶å†…å®¹çš„æ‘˜è¦ä¿¡æ¯"""
            summary = ""
            
            # æå–è¡¨æ ¼summary
            if "è¡¨æ ¼" in file_content and file_content["è¡¨æ ¼"]:
                summary += "è¡¨æ ¼: \n"
                tables = file_content["è¡¨æ ¼"]
                for table_name in tables:
                    if isinstance(tables[table_name], dict) and "summary" in tables[table_name]:
                        summary += f"  {tables[table_name]['summary']}\n"
                    else:
                        summary += f"  {table_name}: [æ— æ‘˜è¦ä¿¡æ¯]\n"
            
            # æå–æ–‡æ¡£summary
            if "æ–‡æ¡£" in file_content and file_content["æ–‡æ¡£"]:
                summary += "\næ–‡æ¡£: \n"
                documents = file_content["æ–‡æ¡£"]
                for doc_name in documents:
                    if isinstance(documents[doc_name], dict) and "summary" in documents[doc_name]:
                        summary += f"  {documents[doc_name]['summary']}\n"
                    else:
                        summary += f"  {doc_name}: [æ— æ‘˜è¦ä¿¡æ¯]\n"
            
            return summary
        
        # åªè¯»å–ç›¸å…³æ‘çš„æ–‡ä»¶
        with open(r'agents\data.json', 'r', encoding = 'utf-8') as f:
            file_content = f.read()
        #     print(template_structure)
        # for key, value in json.loads(file_content).items():
        #     print("key: \n", key)
        #     if key in template_structure:
        #         file_content = value
        #         self.location = key
        file_content = json.loads(file_content)
        self.location = "ç‡•äº‘æ‘"
        self.files_under_location = file_content["ç‡•äº‘æ‘"]
        file_content = extract_summary_for_each_file(self.files_under_location)
        print("===========================")
        print(self.files_under_location)
        

        return {
            "messages": [],
            "chat_history": [],
            "related_files": [],
            "classified_files": {"è¡¨æ ¼": [], "æ–‡æ¡£": []},  # Add default classified files
            "headers_mapping": {},
            "template_structure": template_structure,
            "headers_mapping_": {},
            "file_content": file_content,
            "document_files_content": ""
        }
    

    def _recall_relative_files(self, state: RecallFilesState) -> RecallFilesState:
        """æ ¹æ®è¦ç”Ÿæˆçš„è¡¨æ ¼æ¨¡æ¿ï¼Œä»å‘é‡åº“ä¸­å¬å›ç›¸å…³æ–‡ä»¶"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _recall_relative_files")
        print("=" * 50)
        if state["messages"]:   
            previous_AI_message = state["messages"][-1]
            previous_AI_message_content = previous_AI_message.content
            state["chat_history"].append(previous_AI_message_content)
        chat_history = "\n".join(state["chat_history"])

        print("=========å†å²å¯¹è¯è®°å½•==========")
        print(chat_history)
        print("=========å†å²å¯¹è¯è®°å½•==========")
        
        system_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ–‡ä»¶åˆ†æä¸“å®¶ï¼Œæ“…é•¿ä»æ–‡ä»¶æ‘˜è¦ä¸­ç­›é€‰å‡ºæœ€é€‚åˆç”¨äºå¡«å†™æ¨¡æ¿è¡¨æ ¼çš„æ•°æ®æ–‡ä»¶å’Œè¾…åŠ©å‚è€ƒæ–‡ä»¶ã€‚

ã€ä½ çš„ä»»åŠ¡ã€‘
æ ¹æ®æˆ‘æä¾›çš„è¡¨æ ¼æ¨¡æ¿ç»“æ„ã€ä»»åŠ¡èƒŒæ™¯å’Œæ–‡ä»¶æ‘˜è¦ä¿¡æ¯ï¼Œä»ä¸­æŒ‘é€‰å‡ºå¯èƒ½ç”¨äºå¡«å†™æ¨¡æ¿çš„ç›¸å…³æ–‡ä»¶ï¼Œè¡¨æ ¼æˆ–è€…æ–‡æ¡£æ–‡ä»¶ã€‚

ã€æ‰§è¡Œæµç¨‹ã€‘
ä½ å¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æµç¨‹æ‰§è¡Œï¼š

1. **åˆ†æé˜¶æ®µ**ï¼š
   - åˆ†ææ¨¡æ¿çš„ç»“æ„å­—æ®µï¼Œåˆ¤æ–­å¡«å†™æ‰€éœ€çš„æ•°æ®å’Œå¯èƒ½çš„è®¡ç®—æˆ–è§£é‡Šä¾æ®
   - ä»æ–‡ä»¶æ‘˜è¦ä¸­åˆæ­¥ç­›é€‰ 3~5 ä¸ªé«˜åº¦ç›¸å…³çš„æ–‡ä»¶ï¼Œå¯èƒ½åŒ…æ‹¬ï¼š
     * å«æœ‰åŸå§‹æ•°æ®å­—æ®µçš„ Excel æˆ– CSV æ–‡ä»¶
     * å«æœ‰å­—æ®µè¯´æ˜ã€æ”¿ç­–ä¾æ®ã€è®¡ç®—è§„åˆ™çš„ Word æˆ– PDF æ–‡ä»¶

2. **ç¡®è®¤é˜¶æ®µ**ï¼š
   - **å¿…é¡»è°ƒç”¨å·¥å…· `request_user_clarification` ä¸ç”¨æˆ·ç¡®è®¤ç­›é€‰ç»“æœ**
   - åœ¨å·¥å…·è°ƒç”¨ä¸­ï¼Œå‘ç”¨æˆ·å±•ç¤ºä½ ç­›é€‰çš„æ–‡ä»¶åˆ—è¡¨ï¼Œå¹¶è¯¢é—®æ˜¯å¦åˆé€‚
   - ç­‰å¾…ç”¨æˆ·åé¦ˆåï¼Œæ ¹æ®ç”¨æˆ·æ„è§è°ƒæ•´æ–‡ä»¶é€‰æ‹©ï¼Œå¦‚æœç”¨æˆ·ç»™å‡ºäº†æ­£é¢çš„å›ç­”ï¼Œåˆ™ç›´æ¥è¿”å›æ–‡ä»¶åˆ—è¡¨ï¼Œä¸è¦é‡å¤è°ƒç”¨å·¥å…·

3. **è¾“å‡ºé˜¶æ®µ**ï¼š
   - åªæœ‰åœ¨ç”¨æˆ·ç¡®è®¤åï¼Œæ‰èƒ½è¾“å‡ºæœ€ç»ˆçš„æ–‡ä»¶åˆ—è¡¨
   - è¾“å‡ºæ ¼å¼å¿…é¡»æ˜¯ä¸¥æ ¼çš„ JSON æ•°ç»„ï¼Œä¾‹å¦‚ï¼š["åŸºç¡€ä¿¡æ¯è¡¨.xlsx", "è¡¥è´´æ”¿ç­–è¯´æ˜.docx"]ï¼Œä¸è¦åŒ…è£¹åœ¨```jsonä¸­ï¼Œç›´æ¥è¿”å›jsonæ ¼å¼å³å¯
   - ä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹

ã€é‡è¦è¯´æ˜ã€‘
- æ ¹æ®å†å²å¯¹è¯è®°å½•ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·ï¼Œå½“å¾—åˆ°ç”¨æˆ·ç¡®è®¤åï¼Œä¸éœ€è¦å†è°ƒç”¨å·¥å…·
- ä¸å…è®¸è·³è¿‡ç”¨æˆ·ç¡®è®¤ç›´æ¥è¿”å›æ–‡ä»¶åˆ—è¡¨ï¼Œä½†ä¹Ÿä¸è¦é‡å¤è°ƒç”¨å·¥å…·
- ä¸å…è®¸è‡ªè¡Œä¸ç”¨æˆ·å¯¹è¯ï¼Œå¿…é¡»ä½¿ç”¨ `request_user_clarification` å·¥å…·
- æ–‡ä»¶åä¸å«è·¯å¾„æˆ–æ‘˜è¦å†…å®¹ï¼Œä»…åŒ…å«æ–‡ä»¶å

ã€ä¸¥æ ¼éµå®ˆã€‘
- ä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹ï¼Œä¸è¦è¿”å›ä»»ä½•å…¶ä»–å†…å®¹
- è¿”å›çš„å¿…é¡»æ˜¯æ–‡ä»¶æ•°ç»„ï¼Œä¸”å¿…é¡»ä¸æ–‡ä»¶æ‘˜è¦ä¸­çš„æ–‡ä»¶åä¸€è‡´ï¼Œä¸è¦å°†åºåˆ—å·åŒ…å«åœ¨å†…

è¡¨æ ¼æ¨¡æ¿ç»“æ„ï¼š
{state["template_structure"]}

æ–‡ä»¶æ‘˜è¦åˆ—è¡¨ï¼š
{state["file_content"]}

å†å²å¯¹è¯è®°å½•ï¼š
{chat_history}

è¯·å¼€å§‹æ‰§è¡Œç¬¬ä¸€æ­¥ï¼šåˆ†ææ¨¡æ¿ç»“æ„å¹¶åˆæ­¥ç­›é€‰æ–‡ä»¶ï¼Œç„¶åè°ƒç”¨å·¥å…·ä¸ç”¨æˆ·ç¡®è®¤ã€‚
"""
        print("Garbage fed to our poor LLM: \n", system_prompt)
        response = invoke_model_with_tools(model_name = "gpt-4o", 
                                           messages = [SystemMessage(content = system_prompt)], 
                                           tools=self.tools,
                                           temperature = 0.2)
        response_content = ""
        print("Garbage returned from our LLM: \n", response)
        # invoke_maodel_with_toolsæ°¸è¿œä¸ä¼šè¿”å›str
        if hasattr(response, 'tool_calls') and response.tool_calls:
            question = response.tool_calls[0]['args']['question']
            print("é—®é¢˜ï¼š")
            print(question)
            state["chat_history"].append(question)
            AI_message = response

        else:
            response_content = response.content
            AI_message = AIMessage(content=response_content)
        
        
        
        # Check for tool calls
        has_tool_calls = hasattr(response, 'tool_calls') and response.tool_calls
        if has_tool_calls:
            print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨")
        else:
            print("â„¹ï¸ æ— å·¥å…·è°ƒç”¨")
        
        print("âœ… _recall_relative_files æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        return {
            "messages": [AI_message],
            "related_files_str": response_content
        }


    def _route_after_recall_relative_files(self, state: RecallFilesState) -> str:
        """This node will route the agent to the next node based on the user's input"""
        print("\nğŸ”€ å¼€å§‹æ‰§è¡Œ: _route_after_recall_relative_files")
        print("=" * 50)

        latest_message = state["messages"][-1]
        if hasattr(latest_message, "tool_calls") and latest_message.tool_calls:
            print("ğŸ”§ æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œè·¯ç”±åˆ° request_user_clarification")
            print("âœ… _route_after_recall_relative_files æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "request_user_clarification"
        else:
            print("âœ… æ— å·¥å…·è°ƒç”¨ï¼Œè·¯ç”±åˆ° determine_the_mapping_of_headers")
            print("âœ… _route_after_recall_relative_files æ‰§è¡Œå®Œæˆ")
            print("=" * 50)
            return "determine_the_mapping_of_headers"

    def _classify_files_by_type(self, file_list: list[str], file_content:str ) -> dict[str, list[str]]:
        """Classify the files as è¡¨æ ¼ or æ–‡æ¡£"""

        classified_files = {
            "è¡¨æ ¼": [],
            "æ–‡æ¡£": []
        }

        for file in file_list:
            if file in file_content["æ–‡æ¡£"]:
                classified_files["æ–‡æ¡£"].append(file)
            elif file in file_content["è¡¨æ ¼"]:
                classified_files["è¡¨æ ¼"].append(file)
        print("Classified files: \n", classified_files)
        return classified_files
        

    def _determine_the_mapping_of_headers(self, state: RecallFilesState) -> RecallFilesState:
        """ç¡®è®¤æ¨¡æ¿è¡¨å¤´å’Œæ•°æ®æ–‡ä»¶è¡¨å¤´çš„æ˜ å°„å…³ç³»"""
        print("\nğŸ” å¼€å§‹æ‰§è¡Œ: _determine_the_mapping_of_headers")
        print("=" * 50)
        
        
        # Extract related files from response
        related_files = extract_file_from_recall(state["related_files_str"])
        print(f"ğŸ“‹ éœ€è¦å¤„ç†çš„ç›¸å…³æ–‡ä»¶: {related_files}")
        classified_files = self._classify_files_by_type(related_files, self.files_under_location)
        print("dEBUGBUGBBUBUGB", classified_files)
        
        # è·å–æ‰€æœ‰ç›¸å…³æ–‡ä»¶çš„å†…å®¹
        print("ğŸ“– æ­£åœ¨è¯»å–ç›¸å…³æ–‡ä»¶å†…å®¹...")
        files_content = fetch_related_files_content(classified_files)

        # è·å–æ–‡æ¡£å†…å®¹ï¼š
        print("classified_filesæœ‰ä»€ä¹ˆ: \n", classified_files)
        document_files_content = ""
        for file in classified_files["æ–‡æ¡£"]:
            document_files_content += self.files_under_location["æ–‡æ¡£"][file]["summary"] + "\n"
            print("document_files_content: \n", document_files_content)
        
        # æ„å»ºç”¨äºåˆ†æè¡¨å¤´æ˜ å°„çš„æç¤º
        table_files_content_str = ""
        for filename, content in files_content.items():
            if content:  # åªåŒ…å«æˆåŠŸè¯»å–çš„æ–‡ä»¶
                table_files_content_str += f"\n\n=== {filename} ===\n{content[:1000]}..."  # é™åˆ¶å†…å®¹é•¿åº¦é¿å…è¿‡é•¿

        files_content_str = table_files_content_str + "\n\n" + document_files_content
        print(f"ğŸ“ æ„å»ºäº† {len(files_content)} ä¸ªæ–‡ä»¶çš„å†…å®¹æ‘˜è¦")

        
        system_prompt = f"""
        ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„è¡¨æ ¼åˆ†æä¸“å®¶ï¼Œä»»åŠ¡æ˜¯åˆ†ææ¨¡æ¿è¡¨æ ¼ä¸å¤šä¸ªæ•°æ®æ–‡ä»¶ä¹‹é—´çš„è¡¨å¤´æ˜ å°„å…³ç³»ã€‚

### è¾“å…¥ä¿¡æ¯å¦‚ä¸‹ï¼š

- **æ¨¡æ¿è¡¨æ ¼ç»“æ„**ï¼š
  {state["template_structure"]}

- **ç›¸å…³æ•°æ®æ–‡ä»¶å†…å®¹**ï¼š
  {files_content_str}

### ä»»åŠ¡è¦æ±‚ï¼š

è¯·é€ä¸€å¯¹æ¯”æ¨¡æ¿è¡¨æ ¼ä¸­çš„æ¯ä¸€ä¸ªè¡¨å¤´ï¼Œåˆ†æå…¶åœ¨æ•°æ®æ–‡ä»¶ä¸­å¯¹åº”çš„æ¥æºå­—æ®µã€‚ä½ éœ€è¦å®Œæˆä»¥ä¸‹å‡ é¡¹å·¥ä½œï¼š

1. **å»ºç«‹è¡¨å¤´æ˜ å°„å…³ç³»**ï¼š  
   åœ¨æ¨¡æ¿è¡¨æ ¼ä¸­æ³¨æ˜æ¯ä¸ªè¡¨å¤´å¯¹åº”çš„æ•°æ®æ¥æºâ€”â€”åŒ…æ‹¬æ¥æºæ–‡ä»¶åå’Œå…·ä½“è¡¨å¤´åç§°ã€‚

2. **å¤„ç†ç¼ºå¤±æ˜ å°„çš„å­—æ®µ**ï¼š  
   å¯¹äºæ¨¡æ¿ä¸­æ‰¾ä¸åˆ°ç›´æ¥å¯¹åº”å­—æ®µçš„è¡¨å¤´ï¼Œè¯·å°è¯•åŸºäºå·²æœ‰æ•°æ®è¿›è¡Œæ¨ç†æˆ–æ¨å¯¼ã€‚ä¾‹å¦‚ï¼š
   - åˆ©ç”¨å·²æœ‰å­—æ®µè¿›è¡Œè®¡ç®—ï¼ˆå¦‚"æ€»è®¡"å¯é€šè¿‡åŠ æ€»å…¶ä»–å­—æ®µè·å¾—ï¼‰ï¼›
   - æ ¹æ®æ”¿ç­–æ–‡ä»¶ã€è¯´æ˜æ–‡æ¡£ç­‰è¡¥å……ä¿¡æ¯è¿›è¡Œåˆ¤æ–­ï¼›
   - ä½ éœ€è¦æŠŠè¯¦ç»†å®Œæ•´çš„è¡¨æ ¼å¡«å†™è§„åˆ™å†™å‡ºæ¥ï¼Œä¾‹å¦‚å…·ä½“è¡¥è´´æ•°å­—ç­‰ï¼Œä¸è¦é—æ¼
   - è‹¥æ¶‰åŠç‰¹å®šç­›é€‰æ¡ä»¶ï¼ˆå¦‚"ä»…ç”·æ€§"ã€"ç‰¹å®šå¹´é¾„æ®µ"ã€"æŸåœ°åŒº"ç­‰ï¼‰ï¼Œè¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚è¿›è¡Œé€»è¾‘ç­›é€‰å¹¶å¡«å†™ã€‚

3. **è¾“å‡ºæ ¼å¼è¦æ±‚**ï¼š  
   è¿”å›ç»“æœåº”ä¿æŒä¸åŸæ¨¡æ¿è¡¨æ ¼ç»“æ„ä¸€è‡´ï¼Œä½†æ¯ä¸ªè¡¨å¤´éœ€æ‰©å±•ä¸ºä»¥ä¸‹å½¢å¼ä¹‹ä¸€ï¼š
   - `æ¥æºæ–‡ä»¶å: æ•°æ®å­—æ®µå`ï¼ˆè¡¨ç¤ºè¯¥å­—æ®µæ¥è‡ªæ•°æ®æ–‡ä»¶ï¼‰
   - `æ¨ç†è§„åˆ™: ...`å‘Šè¯‰æ¨¡å‹è¯¥å­—æ®µéœ€è¦é€šè¿‡ä»€ä¹ˆé€»è¾‘æ¨å¯¼å‡ºæ¥ï¼Œå¿…é¡»æŠŠè¯¦ç»†çš„è§„åˆ™ï¼Œæˆ–è€…è®¡ç®—å…¬å¼å†™å‡ºæ¥ï¼Œä¸è¦é—æ¼
   - ä¸è¦å°†è¿”å›ç»“æœåŒ…è£¹åœ¨```jsonä¸­ï¼Œç›´æ¥è¿”å›jsonæ ¼å¼å³å¯


---
è¯·è¿”å›æœ€ç»ˆçš„æ¨¡æ¿è¡¨æ ¼ç»“æ„ï¼Œç¡®ä¿å‡†ç¡®åæ˜ å­—æ®µæ¥æºä¸ç”Ÿæˆé€»è¾‘ï¼Œæ ¼å¼ä¸ä¸Šé¢ä¸€è‡´ï¼Œä¾¿äºåç»­ç¨‹åºè§£æå’Œå¤„ç†ã€‚
        """
        print("ç¡®è®¤è¡¨å¤´æ˜ å°„æç¤ºè¯ï¼š\n", system_prompt)
        print("ğŸ“¤ æ­£åœ¨è°ƒç”¨LLMè¿›è¡Œè¡¨å¤´æ˜ å°„åˆ†æ...")
        response = invoke_model(model_name="Pro/deepseek-ai/DeepSeek-V3", messages=[SystemMessage(content=system_prompt)])
        print("ğŸ“¥ LLMæ˜ å°„åˆ†æå®Œæˆ")
        print("ğŸ’¬ æ™ºèƒ½ä½“å›å¤:")
        print(response)
        print("âœ… _determine_the_mapping_of_headers æ‰§è¡Œå®Œæˆ")
        print("=" * 50)
        
        return {
            "messages": [AIMessage(content=response)],
            "headers_mapping": response,
            "related_files": related_files,
            "classified_files": classified_files,  # Store classified files in state
            "document_files_content": document_files_content
        }
    
    def run_recall_files_agent(self, template_structure: str, session_id: str = "1") -> Dict:
        """è¿è¡Œå¬å›æ–‡ä»¶ä»£ç†ï¼Œä½¿ç”¨invokeæ–¹æ³•è€Œä¸æ˜¯stream"""
        print("\nğŸš€ å¼€å§‹è¿è¡Œ RecallFilesAgent")
        print("=" * 60)

        config = {"configurable": {"thread_id": session_id}}
        initial_state = self._create_initial_state(template_structure)
        
        try:
            # Use invoke instead of stream
            final_state = self.graph.invoke(initial_state, config=config)

            # æå–å¯¹åº”çš„åŸå§‹xlsæ–‡ä»¶
            def extract_original_xls_file(files_under_location: dict[str, dict[str, str]], related_files: list[str]) -> list[str]:
                """Extract the original xls table file from the related files"""
                table_file = files_under_location["è¡¨æ ¼"]
                extract_original_xls_file = []
                for file in related_files:
                    if file in table_file:
                        extract_original_xls_file.append(table_file[file]["original_file_path"])
                return extract_original_xls_file
                    
            
            original_xls_files = extract_original_xls_file(self.files_under_location, final_state.get('related_files', []))
            print("original_xls_filesæœ‰è¿™äº›: \n", original_xls_files)
            
            print("\nğŸ‰ RecallFilesAgent æ‰§è¡Œå®Œæˆï¼")
            print("=" * 60)
            print("ğŸ“Š æœ€ç»ˆç»“æœ:")
            print(f"- å¬å›æ–‡ä»¶æ•°é‡: {len(final_state.get('related_files', []))}")
            print(f"- ç›¸å…³æ–‡ä»¶: {final_state.get('related_files', [])}")
            print(f"- è¡¨å¤´æ˜ å°„å·²ç”Ÿæˆ: {'æ˜¯' if final_state.get('headers_mapping') else 'å¦'}")
            print(f"- è½¬æ¢çš„Excelæ–‡ä»¶æ•°é‡: {len(original_xls_files)}")
            print(f"- è½¬æ¢çš„Excelæ–‡ä»¶: {original_xls_files}")
            
            # Add converted Excel files to the final state
            final_state["original_xls_files"] = original_xls_files
            
            return final_state
            
        except Exception as e:
            print(f"âŒ æ‰§è¡Œè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            return initial_state


if __name__ == "__main__":
    agent = RecallFilesAgent()
    
    # Example template structure for testing
    sample_template_structure = """
    {
        "è¡¨æ ¼ç»“æ„": {
        "é‡åº†å¸‚å·´å—åŒºäº«å—ç”Ÿæ´»è¡¥è´´è€å…šå‘˜ç™»è®°è¡¨": {
            "åŸºæœ¬ä¿¡æ¯": [
                "åºå·",
                "å§“å",
                "æ€§åˆ«",
                "æ°‘æ—",
                "èº«ä»½è¯å·ç ",
                "å‡ºç”Ÿæ—¶é—´",
                "æ‰€åœ¨å…šæ”¯éƒ¨",
                "æˆä¸ºæ­£å¼å…šå‘˜æ—¶é—´",
                "å…šé¾„ï¼ˆå¹´ï¼‰",
                "ç”Ÿæ´»è¡¥è´´æ ‡å‡†ï¼ˆå…ƒï¼æœˆï¼‰",
                "å¤‡æ³¨"
            ]
        }
            },
    "è¡¨æ ¼æ€»ç»“": "è¯¥è¡¨æ ¼ç”¨äºé‡åº†å¸‚å·´å—åŒºç‡•äº‘æ‘å…šå§”ç™»è®°äº«å—ç”Ÿæ´»è¡¥è´´çš„è€å…šå‘˜ä¿¡æ¯ï¼ŒåŒ…å«å…šå‘˜ä¸ªäººèº«ä»½ä¿¡æ¯ã€å…šé¾„ã€è¡¥è´´æ ‡å‡†ç­‰æ ¸å¿ƒå­—æ®µï¼Œé€‚ç”¨äºåŸºå±‚å…šç»„ç»‡å¯¹è€å…šå‘˜è¡¥è´´å‘æ”¾çš„ç»Ÿè®¡ç®¡ç†ã€‚" 
    }
    """
    
    agent.run_recall_files_agent(template_structure=sample_template_structure)


