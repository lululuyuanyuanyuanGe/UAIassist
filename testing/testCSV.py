import sys
from pathlib import Path
import io
import contextlib

# Add root project directory to sys.path
sys.path.append(str(Path(__file__).resolve().parent.parent))



from typing import Dict, List, Optional, Any, TypedDict, Annotated
from datetime import datetime
from utilities.visualize_graph import save_graph_visualization
from utilities.message_process import build_BaseMessage_type, filter_out_system_messages
from utilities.file_process import detect_and_process_file_paths, retrieve_file_content, read_txt_file, process_excel_files_with_chunking, clean_and_pretty_print_csv
from utilities.modelRelated import invoke_model

import uuid
import json
import os
import pandas as pd
from bs4 import BeautifulSoup
from pathlib import Path
# Create an interactive chatbox using gradio
import gradio as gr
from dotenv import load_dotenv
import re

from langgraph.graph import StateGraph, END, START
from langgraph.graph.message import add_messages
# from langgraph.checkpoint.sqlite import SqliteSaver
from langgraph.prebuilt import ToolNode
from langgraph.checkpoint.memory import MemorySaver
from langgraph.types import Command, Interrupt, interrupt
from langchain_core.messages import HumanMessage, AIMessage, BaseMessage, SystemMessage
from langchain_core.tools import tool


# import other agents
from agents.processUserInput import ProcessUserInputAgent

load_dotenv()


def combine_data_split_into_chunks(file_path: list[str]) -> list[str]:
        """æ•´åˆæ‰€æœ‰éœ€è¦ç”¨åˆ°çš„æ•°æ®ï¼Œå¹¶ç”Ÿå°†å…¶åˆ†æ‰¹ï¼Œç”¨äºåˆ†æ‰¹ç”Ÿæˆè¡¨æ ¼"""
        try:
            # Get Excel file paths from state
            excel_file_paths = []
            
            # Convert data files to Excel paths if they're not already
            for file_path in file_path:
                if file_path.endswith('.txt'):
                    # Try to find corresponding Excel file
                    excel_path = file_path.replace('.txt', '.xlsx')
                    if Path(excel_path).exists():
                        excel_file_paths.append(excel_path)
                    else:
                        # Try .xls extension
                        excel_path = file_path.replace('.txt', '.xls')
                        if Path(excel_path).exists():
                            excel_file_paths.append(excel_path)
                elif file_path.endswith(('.xlsx', '.xls', '.xlsm')):
                    excel_file_paths.append(file_path)
            
            if not excel_file_paths:
                print("âš ï¸ No Excel files found for chunking")
                return []
            
            print(f"ğŸ“Š Processing {len(excel_file_paths)} Excel files for chunking")
            
            # Use the helper function to process and chunk files
            # Convert word_file_list to string for supplement content

            supplement_content = "1. é‡åº†å¸‚å·´å—åŒºå…šå†…å…³æ€€åŠæ³•ï¼ˆä¿®è®¢ï¼‰æ˜ç¡®å…³æ€€å¯¹è±¡ä¸ºä¸‰ç±»ï¼šå…šé¾„40å¹´åŠä»¥ä¸Šçš„å†œæ‘è€å…šå‘˜å’Œæœªäº«å—åŸé•‡å…»è€ä¿é™©æˆ–ç¦»é€€ä¼‘å¾…é‡çš„åŸé•‡è€å…šå‘˜ï¼›å¹´æ»¡80å‘¨å²ä¸”å…šé¾„55å¹´åŠä»¥ä¸Šçš„è€å…šå‘˜ï¼›ä»¥åŠå› é‡å¤§ç–¾ç—…ã€ç¾éš¾ã€å˜æ•…ç­‰å¯¼è‡´å®¶åº­ç”Ÿæ´»ç‰¹åˆ«å›°éš¾çš„å…šå‘˜ã€‚2. æ•¬è€è¡¥åŠ©æ ‡å‡†æŒ‰å…šé¾„å¹´é™åˆ†æ¡£æ‰§è¡Œï¼šå…šé¾„40-49å¹´è¡¥åŠ©100å…ƒ/æœˆï¼Œ50-54å¹´è¡¥åŠ©120å…ƒ/æœˆï¼Œ55å¹´åŠä»¥ä¸Šè¡¥åŠ©150å…ƒ/æœˆï¼Œè¡¥åŠ©è‡ªç¬¦åˆæ¡ä»¶æ¬¡æœˆèµ·æŒ‰æœˆå‘æ”¾ï¼Œæ ‡å‡†éšå¸‚çº§æ”¿ç­–è°ƒæ•´ã€‚"
            
            chunked_data = process_excel_files_with_chunking(excel_file_paths, supplement_content)

            return chunked_data
            
        except Exception as e:
            print(f"âŒ Error in _combine_data_split_into_chunks: {e}")
            return []



def generate_CSV_based_on_combined_data(chunk_data: list[str]) -> str:
        """æ ¹æ®æ•´åˆçš„æ•°æ®ï¼Œæ˜ å°„å…³ç³»ï¼Œæ¨¡æ¿ç”Ÿæˆæ–°çš„æ•°æ®"""
        system_prompt = f"""
ä½ æ˜¯ä¸€ä½ç²¾é€šè¡¨æ ¼æ•°æ®è§£æä¸å¡«æŠ¥çš„ä¸“å®¶åŠ©æ‰‹ã€‚ç”¨æˆ·å°†æä¾›ä¸€ä¸ªåŒ…å«å¤šä¸ª CSV æ ¼å¼çš„ Excel æ•°æ®æ–‡ä»¶çš„æ•°æ®é›†åˆã€‚

è¿™äº›æ–‡ä»¶å­˜åœ¨ä»¥ä¸‹ç‰¹ç‚¹ä¸è¾…åŠ©ä¿¡æ¯ï¼š
1. ç”±äº CSV æ ¼å¼æ— æ³•å®Œæ•´è¡¨è¾¾å¤æ‚çš„è¡¨å¤´ç»“æ„ï¼Œç³»ç»Ÿå°†æä¾›ä¸€ä»½ç”±å­—å…¸æ„æˆçš„è¡¨å¤´ç»“æ„è¯´æ˜ï¼Œä»¥å¸®åŠ©ä½ å‡†ç¡®ç†è§£æ¯ä¸ªæ–‡ä»¶çš„è¡¨æ ¼å¸ƒå±€ï¼›
2. åŒæ—¶è¿˜ä¼šæä¾›ä¸€ä»½"å­—æ®µæ˜ å°„å…³ç³»è¡¨"ï¼Œæ˜ç¡®æŒ‡å‡ºæ¨¡æ¿è¡¨æ ¼ä¸­çš„æ¯ä¸€åˆ—æ•°æ®åº”å¦‚ä½•ä»åŸå§‹æ•°æ®æ–‡ä»¶ä¸­æå–ï¼ŒåŒ…æ‹¬ï¼š
   - ç›´æ¥å¯¹åº”æŸä¸€åˆ—ï¼›
   - ç”±å¤šåˆ—ç»„åˆè®¡ç®—å¾—åˆ°ï¼›
   - æˆ–éœ€ä¾æ®è¡¥å……è§„åˆ™è¿›è¡Œé€»è¾‘æ¨ç†æˆ–æ¡ä»¶åˆ¤æ–­å¾—å‡ºã€‚

ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„æ•°æ®é›†ã€è¡¨å¤´ç»“æ„è¯´æ˜ä¸å­—æ®µæ˜ å°„è§„åˆ™ï¼Œè‡ªåŠ¨ç”Ÿæˆç”¨äºå¡«å†™æ¨¡æ¿è¡¨æ ¼çš„æ•°æ®å†…å®¹ã€‚

æœ€ç»ˆè¾“å‡ºæ ¼å¼è¦æ±‚ï¼š
- ä¸éœ€è¦ç”Ÿæˆä»»ä½•è§£é‡Šï¼Œä¸è¦åŠ å…¥CSVæ ‡ç­¾
- ä¸è¦ç”Ÿæˆè¡¨å¤´ï¼Œåªç”Ÿæˆæ•°æ®
- è¾“å‡ºä¸ºä¸¥æ ¼éµå¾ª CSV æ ¼å¼çš„çº¯æ–‡æœ¬ï¼›
- æ¯ä¸€è¡Œä»£è¡¨æ¨¡æ¿è¡¨æ ¼ä¸­çš„ä¸€æ¡è®°å½•ï¼›
- ä¸åŒ…å«å¤šä½™ä¿¡æ¯æˆ–æ³¨é‡Šï¼Œä»…ä¿ç•™æ•°æ®æœ¬èº«ã€‚

è¯·ç¡®ä¿ä½ å®Œæ•´è§£ææ¯ä¸ªå­—æ®µè§„åˆ™ï¼Œæ­£ç¡®å¤„ç†è®¡ç®—ä¸æ¨ç†é€»è¾‘ï¼Œç”Ÿæˆç»“æ„å‡†ç¡®ã€å†…å®¹å®Œæ•´çš„è¡¨æ ¼æ•°æ®ã€‚
"""
        
        def process_single_chunk(chunk_data):
            """å¤„ç†å•ä¸ªchunkçš„å‡½æ•°"""
            chunk, index = chunk_data
            try:
                user_input = f"""
{chunk}

"è¡¨æ ¼ç»“æ„": {{
    "é‡åº†å¸‚å·´å—åŒºäº«å—ç”Ÿæ´»è¡¥è´´è€å…šå‘˜ç™»è®°è¡¨": {{  
      "åºå·": [],
      "å§“å": [],
      "æ€§åˆ«": [],
      "æ°‘æ—": [],
      "èº«ä»½è¯å·ç ": [],
      "å‡ºç”Ÿæ—¶é—´": [],
      "æ‰€åœ¨å…šæ”¯éƒ¨": [],
      "æˆä¸ºæ­£å¼å…šå‘˜æ—¶é—´": [],
      "å…šé¾„ï¼ˆå¹´ï¼‰": [],
      "ç”Ÿæ´»è¡¥è´´æ ‡å‡†ï¼ˆå…ƒï¼æœˆï¼‰": [],
      "å¤‡æ³¨": []
    }}
}}
"""
                print(f"ğŸ¤– Processing chunk {index + 1}...")
                response = invoke_model(
                    model_name="deepseek-ai/DeepSeek-V3", 
                    messages=[SystemMessage(content=system_prompt), HumanMessage(content=user_input)]
                )
                print(f"âœ… Completed chunk {index + 1}")
                return (index, response)
            except Exception as e:
                print(f"âŒ Error processing chunk {index + 1}: {e}")
                return (index, f"Error processing chunk {index + 1}: {e}")
        
        # Prepare chunk data with indices
        chunks_with_indices = [(chunk, i) for i, chunk in enumerate(chunk_data)]
        
        if not chunks_with_indices:
            print("âš ï¸ No chunks to process")
            return []
        
        print(f"ğŸš€ Starting concurrent processing of {len(chunks_with_indices)} chunks...")
        
        # Use ThreadPoolExecutor for concurrent processing
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        results = {}
        with ThreadPoolExecutor(max_workers=5) as executor:  # Limit to 3 concurrent requests
            # Submit all tasks
            future_to_index = {executor.submit(process_single_chunk, chunk_data): chunk_data[1] 
                              for chunk_data in chunks_with_indices}
            
            # Collect results as they complete
            for future in as_completed(future_to_index):
                try:
                    index, response = future.result()
                    results[index] = response
                except Exception as e:
                    index = future_to_index[future]
                    print(f"âŒ Exception in chunk {index + 1}: {e}")
                    results[index] = f"Exception in chunk {index + 1}: {e}"
        
        # Sort results by index to maintain order
        sorted_results = [results[i] for i in sorted(results.keys())]
        
        print(f"ğŸ‰ Successfully processed {len(sorted_results)} chunks concurrently")
        
        return sorted_results




file_path = [r"D:\asianInfo\ExcelAssist\ç‡•äº‘æ‘case\ç‡•äº‘æ‘2024å¹´åº¦å…šå‘˜åå†Œ.xlsx"]
chunked_data = combine_data_split_into_chunks(file_path)

print("\n" + "="*80)
print("ğŸš€ Starting CSV data generation with concurrent processing...")
print("="*80)

data = generate_CSV_based_on_combined_data(chunked_data)

print("\n" + "="*80)
print("ğŸ“Š Pretty printing cleaned CSV data...")
print("="*80)

# Use the pretty print function to clean and display the data nicely
cleaned_df = clean_and_pretty_print_csv(data, output_file="testing/cleaned_å…šå‘˜è¡¥è´´_output.csv")