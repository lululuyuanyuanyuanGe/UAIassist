from __future__ import annotations
from bs4 import BeautifulSoup, Tag
from pathlib import Path

from typing import TypedDict, Annotated, List
import re
import os
from pathlib import Path
import subprocess
import chardet

from openai import OpenAI
from langchain_core.messages import HumanMessage, BaseMessage, SystemMessage


def build_BaseMessage_type(messages:list[dict], file_paths : list[str] = None) -> list[BaseMessage]:
    """"å°†æ¶ˆæ¯é˜Ÿåˆ—è½¬æ¢æˆLangChainçš„æ¶ˆæ¯æ¨¡æ¿"""
    langchain_messages = []
    for msg in messages:
        if msg["role"] == "system":
            langchain_messages.append(SystemMessage(content = msg["content"]))
        elif msg["role"] == "user":
            # åˆ¤æ–­æ˜¯å¦ä¸ºå¤æ‚è¾“å…¥(åŒ…å«æ–‡ä»¶)
            if isinstance(msg["content"], list):
                # å°†ç”¨æˆ·æ–‡æœ¬è¾“å…¥å­˜å‚¨åœ¨ contenxt_text
                contexnt_text = next((item["text"] for item in msg["content"] if item["type"] == "text"), "")
                file_refs = [item["file_id"] for item in msg["content"] if item["type"] == "input_file"]
                user_input = F"{contexnt_text} + input files list: {' '.join(file_refs)}"
                human_msg = HumanMessage(
                    content= user_input,
                    additional_kargs = {
                        "filer_ids": file_refs,
                        "multimodal_content": msg["content"]
                    }
                )
                langchain_messages.append(human_msg)
        else:
            langchain_messages.append(HumanMessage(content=msg["content"]))

    return langchain_messages

def filter_out_system_messages(messages: List[BaseMessage]) -> List[BaseMessage]:
    """è¾…åŠ©å‡½æ•°è¿‡æ»¤æ¶ˆæ¯é˜Ÿåˆ—ä¸­çš„ç³»ç»Ÿæç¤ºè¯æ¶ˆæ¯"""
    return [message for message in messages if not isinstance(message, SystemMessage)]

def detect_and_process_file_paths(user_input: str) -> list:
    """æ£€æµ‹ç”¨æˆ·è¾“å…¥ä¸­çš„æ–‡ä»¶è·¯å¾„å¹¶éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œè¿”å›žç»“æžœä¸ºç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶è·¯å¾„ç»„æˆçš„æ•°åˆ—"""
    file_paths = []
    
    # æ”¹è¿›çš„æ–‡ä»¶è·¯å¾„æ£€æµ‹æ¨¡å¼ï¼Œæ”¯æŒä¸­æ–‡å­—ç¬¦
    # Windowsè·¯å¾„æ¨¡å¼ (C:\path\file.ext æˆ– D:\path\file.ext) - æ”¯æŒä¸­æ–‡å­—ç¬¦
    windows_pattern = r'[A-Za-z]:[\\\\/](?:[^\\\\/\s\n\r]+[\\\\/])*[^\\\\/\s\n\r]+\.\w+'
    # ç›¸å¯¹è·¯å¾„æ¨¡å¼ (./path/file.ext æˆ– ../path/file.ext) - æ”¯æŒä¸­æ–‡å­—ç¬¦
    relative_pattern = r'\.{1,2}[\\\\/](?:[^\\\\/\s\n\r]+[\\\\/])*[^\\\\/\s\n\r]+\.\w+'
    # ç®€å•æ–‡ä»¶åæ¨¡å¼ (filename.ext) - æ”¯æŒä¸­æ–‡å­—ç¬¦
    filename_pattern = r'\b[a-zA-Z0-9_\u4e00-\u9fff\-\(\)ï¼ˆï¼‰]+\.[a-zA-Z0-9]+\b'
    
    patterns = [windows_pattern, relative_pattern, filename_pattern]
    
    for pattern in patterns:
        matches = re.findall(pattern, user_input)
        for match in matches:
            # éªŒè¯æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if os.path.exists(match):
                file_paths.append(match)
                print(f"âœ… æ£€æµ‹åˆ°æ–‡ä»¶: {match}")
            else:
                print(f"âš ï¸ æ–‡ä»¶è·¯å¾„æ— æ•ˆæˆ–æ–‡ä»¶ä¸å­˜åœ¨: {match}")
    
    return file_paths

def upload_file_to_LLM(file_paths: list, provider: str = "openai", purpose: str = "assistants", vector_store_id: str = None):
    """
    é€šç”¨æ–‡ä»¶ä¸Šä¼ å·¥å…·ï¼Œæ”¯æŒå¤šä¸ªæ¨¡åž‹æä¾›å•†
    """
    results = {
        "provider": provider,
        "uploaded_files": [],
        "failed_files": [],
        "vector_store_files": [],
        "total_files": len(file_paths)
    }
    
    if provider.lower() == "openai":
        return _upload_to_openai(file_paths, purpose, vector_store_id, results)
    # elif provider.lower() == "azure":
    #     return _upload_to_azure(file_paths, purpose, vector_store_id, results)
    # elif provider.lower() == "anthropic":
    #     return _upload_to_anthropic(file_paths, purpose, results)
    # elif provider.lower() == "local":
    #     return _upload_to_local(file_paths, purpose, results)
    else:
        results["error"] = f"Unsupported provider: {provider}"
        return results


def _upload_to_openai(file_paths: list, purpose: str, vector_store_id: str, results: dict):
    """OpenAI æ–‡ä»¶ä¸Šä¼ å®žçŽ°"""
    from openai import OpenAI
    import os
    
    try:
        client = OpenAI(api_key=os.environ.get("OPENAI_API_KEY"))
        
        for file_path in file_paths:
            try:
                file_path = Path(file_path)
                if not file_path.exists():
                    results["failed_files"].append({
                        "file": str(file_path),
                        "error": "File not found"
                    })
                    continue
                
                print(f"ðŸ“ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶: {file_path.name}")
                
                # ä¸Šä¼ æ–‡ä»¶åˆ°OpenAI
                with open(file_path, 'rb') as file:
                    file_response = client.files.create(
                        file=file,
                        purpose=purpose
                    )
                
                uploaded_file_info = {
                    "file_id": file_response.id,
                    "filename": file_response.filename,
                    "purpose": file_response.purpose,
                    "size": file_response.bytes,
                    "created_at": file_response.created_at
                }
                
                results["uploaded_files"].append(uploaded_file_info)
                print(f"âœ… æ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_response.filename} (ID: {file_response.id})")
                
                # å¦‚æžœæä¾›äº†vector_store_idï¼Œå°†æ–‡ä»¶æ·»åŠ åˆ°å‘é‡å­˜å‚¨
                if vector_store_id:
                    try:
                        vector_file_response = client.beta.vector_stores.files.create(
                            vector_store_id=vector_store_id,
                            file_id=file_response.id
                        )
                        
                        results["vector_store_files"].append({
                            "vector_store_id": vector_store_id,
                            "file_id": file_response.id,
                            "status": vector_file_response.status
                        })
                        print(f"âœ… æ–‡ä»¶å·²æ·»åŠ åˆ°å‘é‡å­˜å‚¨: {vector_store_id}")
                        
                    except Exception as vs_error:
                        print(f"âš ï¸ å‘é‡å­˜å‚¨æ·»åŠ å¤±è´¥: {vs_error}")
                        results["failed_files"].append({
                            "file": str(file_path),
                            "error": f"Vector store upload failed: {vs_error}"
                        })
                
            except Exception as file_error:
                print(f"âŒ æ–‡ä»¶ä¸Šä¼ å¤±è´¥ {file_path.name}: {file_error}")
                results["failed_files"].append({
                    "file": str(file_path),
                    "error": str(file_error)
                })
        
        results["success"] = True
        results["message"] = f"OpenAIä¸Šä¼ å®Œæˆ: {len(results['uploaded_files'])}ä¸ªæˆåŠŸ, {len(results['failed_files'])}ä¸ªå¤±è´¥"
        
    except Exception as e:
        results["success"] = False
        results["error"] = f"OpenAI APIé”™è¯¯: {str(e)}"
    
    return results

# ç›®å‰åªç”¨åˆ°äº†OpenAIçš„æ¨¡åž‹

# def _upload_to_azure(file_paths: list, purpose: str, vector_store_id: str, results: dict):
#     """Azure OpenAI æ–‡ä»¶ä¸Šä¼ å®žçŽ°"""
#     try:
#         from openai import AzureOpenAI
#         import os
        
#         client = AzureOpenAI(
#             api_key=os.environ.get("AZURE_OPENAI_API_KEY"),
#             api_version=os.environ.get("OPENAI_API_VERSION", "2024-02-15-preview"),
#             azure_endpoint=os.environ.get("AZURE_OPENAI_ENDPOINT")
#         )
        
#         for file_path in file_paths:
#             try:
#                 file_path = Path(file_path)
#                 if not file_path.exists():
#                     results["failed_files"].append({
#                         "file": str(file_path),
#                         "error": "File not found"
#                     })
#                     continue
                
#                 print(f"ðŸ“ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°Azure: {file_path.name}")
                
#                 with open(file_path, 'rb') as file:
#                     file_response = client.files.create(
#                         file=file,
#                         purpose=purpose
#                     )
                
#                 results["uploaded_files"].append({
#                     "file_id": file_response.id,
#                     "filename": file_response.filename,
#                     "purpose": file_response.purpose,
#                     "provider": "azure"
#                 })
#                 print(f"âœ… Azureæ–‡ä»¶ä¸Šä¼ æˆåŠŸ: {file_response.filename}")
                
#             except Exception as file_error:
#                 print(f"âŒ Azureæ–‡ä»¶ä¸Šä¼ å¤±è´¥ {file_path.name}: {file_error}")
#                 results["failed_files"].append({
#                     "file": str(file_path),
#                     "error": str(file_error)
#                 })
        
#         results["success"] = True
#         results["message"] = f"Azureä¸Šä¼ å®Œæˆ: {len(results['uploaded_files'])}ä¸ªæˆåŠŸ"
        
#     except ImportError:
#         results["success"] = False
#         results["error"] = "Azure OpenAI library not installed. Run: pip install openai[azure]"
#     except Exception as e:
#         results["success"] = False
#         results["error"] = f"Azure APIé”™è¯¯: {str(e)}"
    
#     return results


# def _upload_to_anthropic(file_paths: list, purpose: str, results: dict):
#     """Anthropic Claude æ–‡ä»¶ä¸Šä¼ å®žçŽ°"""
#     try:
#         import anthropic
#         import os
        
#         client = anthropic.Anthropic(api_key=os.environ.get("ANTHROPIC_API_KEY"))
        
#         for file_path in file_paths:
#             try:
#                 file_path = Path(file_path)
#                 if not file_path.exists():
#                     results["failed_files"].append({
#                         "file": str(file_path),
#                         "error": "File not found"
#                     })
#                     continue
                
#                 print(f"ðŸ“ æ­£åœ¨ä¸Šä¼ æ–‡ä»¶åˆ°Anthropic: {file_path.name}")
                
#                 # æ³¨æ„ï¼šAnthropicçš„æ–‡ä»¶ä¸Šä¼ APIå¯èƒ½ä¸åŒï¼Œè¿™é‡Œæ˜¯ç¤ºä¾‹
#                 # å®žé™…å®žçŽ°éœ€è¦æ ¹æ®Anthropicçš„å…·ä½“APIè°ƒæ•´
#                 with open(file_path, 'rb') as file:
#                     file_content = file.read()
                
#                 results["uploaded_files"].append({
#                     "filename": file_path.name,
#                     "size": len(file_content),
#                     "provider": "anthropic",
#                     "note": "Anthropic files are typically handled differently"
#                 })
#                 print(f"âœ… Anthropicæ–‡ä»¶å¤„ç†å®Œæˆ: {file_path.name}")
                
#             except Exception as file_error:
#                 print(f"âŒ Anthropicæ–‡ä»¶å¤„ç†å¤±è´¥ {file_path.name}: {file_error}")
#                 results["failed_files"].append({
#                     "file": str(file_path),
#                     "error": str(file_error)
#                 })
        
#         results["success"] = True
#         results["message"] = f"Anthropicå¤„ç†å®Œæˆ: {len(results['uploaded_files'])}ä¸ªæ–‡ä»¶"
        
#     except ImportError:
#         results["success"] = False
#         results["error"] = "Anthropic library not installed. Run: pip install anthropic"
#     except Exception as e:
#         results["success"] = False
#         results["error"] = f"Anthropic APIé”™è¯¯: {str(e)}"
    
#     return results


# def _upload_to_local(file_paths: list, purpose: str, results: dict):
#     """æœ¬åœ°æ–‡ä»¶å¤„ç†å®žçŽ°"""
#     import shutil
#     import os
#     from datetime import datetime
    
#     try:
#         # åˆ›å»ºæœ¬åœ°å­˜å‚¨ç›®å½•
#         local_storage = Path("uploaded_files")
#         local_storage.mkdir(exist_ok=True)
        
#         for file_path in file_paths:
#             try:
#                 file_path = Path(file_path)
#                 if not file_path.exists():
#                     results["failed_files"].append({
#                         "file": str(file_path),
#                         "error": "File not found"
#                     })
#                     continue
                
#                 print(f"ðŸ“ æ­£åœ¨å¤„ç†æœ¬åœ°æ–‡ä»¶: {file_path.name}")
                
#                 # å¤åˆ¶æ–‡ä»¶åˆ°æœ¬åœ°å­˜å‚¨
#                 destination = local_storage / f"{datetime.now().strftime('%Y%m%d_%H%M%S')}_{file_path.name}"
#                 shutil.copy2(file_path, destination)
                
#                 results["uploaded_files"].append({
#                     "original_path": str(file_path),
#                     "stored_path": str(destination),
#                     "filename": file_path.name,
#                     "size": file_path.stat().st_size,
#                     "provider": "local"
#                 })
#                 print(f"âœ… æœ¬åœ°æ–‡ä»¶å­˜å‚¨æˆåŠŸ: {destination}")
                
#             except Exception as file_error:
#                 print(f"âŒ æœ¬åœ°æ–‡ä»¶å¤„ç†å¤±è´¥ {file_path.name}: {file_error}")
#                 results["failed_files"].append({
#                     "file": str(file_path),
#                     "error": str(file_error)
#                 })
        
#         results["success"] = True
#         results["message"] = f"æœ¬åœ°å­˜å‚¨å®Œæˆ: {len(results['uploaded_files'])}ä¸ªæ–‡ä»¶"
        
#     except Exception as e:
#         results["success"] = False
#         results["error"] = f"æœ¬åœ°å­˜å‚¨é”™è¯¯: {str(e)}"
    
#     return results

def convert_excel_2_html(input_path: str | Path, output_dir: str | Path) -> Path:
    """
    Convert an Excel workbook to a minimal HTML file that contains only the
    table structure.  Returns the *cleaned* HTML path.

    Notes
    -----
    â€¢ LibreOffice writes `<workbook-stem>.html` into *output_dir*.  
    â€¢ Because *output_dir* is reserved exclusively for these exports, we can
      compute that file name directly instead of searching for it.
    """
    input_path  = Path(input_path).expanduser().resolve()
    output_dir  = Path(output_dir).expanduser().resolve()
    output_dir.mkdir(parents=True, exist_ok=True)

    # 1ï¸âƒ£  LibreOffice export --------------------------------------------------
    soffice = r"D:\LibreOffice\program\soffice.exe"      # adjust if necessary
    subprocess.run(
        [soffice, "--headless", "--convert-to", "html", str(input_path),
         "--outdir", str(output_dir)],
        check=True
    )

    # 2ï¸âƒ£  The raw export path we expect LibreOffice to create
    raw_html_path = output_dir / f"{input_path.stem}.html"
    if not raw_html_path.exists():
        raise FileNotFoundError(f"LibreOffice did not create {raw_html_path}")

    # 3ï¸âƒ£  Clean & return the tidy file
    return _clean_html(raw_html_path, output_dir)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ private helpers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ #
def _read_text_auto(path: Path) -> str:
    """Best-effort text loader with encoding detection."""
    data = path.read_bytes()
    for enc in ("utf-8", "utf-8-sig", "gb18030", "gbk", "big5"):
        try:
            return data.decode(enc)
        except UnicodeDecodeError:
            continue
    if chardet:
        enc = chardet.detect(data).get("encoding")
        if enc:
            try:
                return data.decode(enc)
            except UnicodeDecodeError:
                pass
    return data.decode("utf-8", errors="replace")


def _clean_html(raw_html_path: Path, out_dir: Path) -> Path:
    """
    Strip Excel/Sheets boiler-plateâ€”*including the massive inline CSS*â€”and keep
    only genuine table markup.

    â€¢ Preserves:  <table>, <thead>, <tbody>, <tfoot>, <tr>, <td>, <th>,
                 <col>, <colgroup>
    â€¢ Keeps attributes:  rowspan/colspan everywhere, plus span on <colgroup>.
    """
    KEEP          = {"table", "thead", "tbody", "tfoot", "tr", "td",
                     "th", "col", "colgroup"}
    ATTR_ALWAYS   = {"rowspan", "colspan"}
    ATTR_EXTRA    = {"colgroup": {"span"}}

    html = _read_text_auto(raw_html_path)

    # drop DOCTYPE / XML prologs
    html = re.sub(r'<!DOCTYPE[^>]*?>',           '', html, flags=re.I | re.S)
    html = re.sub(r'<\?xml[^>]*?\?>',            '', html, flags=re.I)
    html = re.sub(r'<\?mso-application[^>]*?\?>','', html, flags=re.I)

    soup = BeautifulSoup(html, "html.parser")

    # remove <style>, <meta>, <link>
    for t in soup.find_all(["style", "meta", "link"]):
        t.decompose()

    # prune unwanted tags / attributes
    for t in soup.find_all(True):
        if t.name not in KEEP:
            t.unwrap()
            continue
        allowed = ATTR_ALWAYS | ATTR_EXTRA.get(t.name, set())
        t.attrs = {k: v for k, v in t.attrs.items() if k in allowed}

    # build minimal shell
    shell = BeautifulSoup("<html><body></body></html>", "html.parser")
    for tbl in soup.find_all("table"):
        shell.body.append(tbl)

    out_file = out_dir / f"{raw_html_path.stem}_clean.html"
    out_file.write_text(shell.prettify(), encoding="utf-8")
    return out_file


